window.COURSE_DATA = {"language":"en-AU-x-unimelb","lastDownload":"2020-05-21T16:52:15+10:00","title":"Natural Language Processing (COMP90042_2020_SM1)","modules":[{"id":301745,"name":"Welcome","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"gec17b2e7878c78c27afd777f7bfa7b94","items":[{"id":1296491,"title":"Staff information","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003ch2\u003eSubject Co-ordinator\u003c/h2\u003e\r\n\u003cp\u003eJey Han Lau / \u003ca href=\"mailto:laujh@unimelb.edu.au\" target=\"_blank\"\u003elaujh@unimelb.edu.au\u003c/a\u003e\u003cem\u003e\u003cbr\u003e\u003c/em\u003e\u003c/p\u003e\r\n\u003cp\u003eOffice: Doug McDonell 3.25\u003c/p\u003e\r\n\u003cp\u003eOffice hours: by appointment\u003c/p\u003e\r\n\u003ch2\u003e \u003c/h2\u003e\r\n\u003ch2\u003eHead Tutor\u003c/h2\u003e\r\n\u003cp\u003eZenan Zhai / \u003ca href=\"mailto:zenanz@student.unimelb.edu.au\" target=\"_blank\"\u003ezenan.zhai@unimelb.edu.au\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2\u003e \u003c/h2\u003e\r\n\u003ch2\u003eSubject tutors\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eAili Shen / \u003ca href=\"mailto:aili.shen@unimelb.edu.au\" target=\"_blank\"\u003eailis@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eBiaoyan Fang / \u003ca href=\"mailto:biaoyanf@student.unimelb.edu.au\" target=\"_blank\"\u003ebiaoyan@unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eDalin Wang / \u003ca href=\"mailto:dalinw@student.unimelb.edu.au\" target=\"_blank\"\u003edalinw@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eFajri Koto / \u003ca href=\"mailto:ffajri@student.unimelb.edu.au\" target=\"_blank\"\u003efajrif@unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eHaonan Li / \u003ca href=\"mailto:haonanl5@student.unimelb.edu.au\" target=\"_blank\"\u003ehaonanl5@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eJun Wang / \u003ca href=\"mailto:jun5@unimelb.edu.au\" target=\"_blank\"\u003ejun5@unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eNitika Mathur / \u003ca href=\"mailto:nmathur@student.unimelb.edu.au\" target=\"_blank\"\u003enmathur@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"staff-information"},{"id":1690545,"title":"Machine Learning Readings","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThe subject assumes foundational knowledge of machine learning. The following readings are good sources on this topic:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eE18\u003c/strong\u003e: Eisenstein, Jacob; \u003ca title=\"e18.pdf\" href=\"viewer/files/e18.pdf?canvas_download=1\" name=\"e18.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2586500\" data-api-returntype=\"File\"\u003e\u003ci\u003eNatural Language Processing\u003c/i\u003e\u003c/a\u003e.\r\n\u003cul\u003e\r\n\u003cli\u003eProbability and optimisation: Appendix A \u0026amp; B\u003c/li\u003e\r\n\u003cli\u003eLinear classifiers: Chapter 2\u003c/li\u003e\r\n\u003cli\u003eNeural networks: Chapter 3\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e","exportId":"machine-learning-readings"}]},{"id":367220,"name":"Lectures","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g0b3e05c256490a85960190846241606a","items":[{"id":1678196,"title":"Slides","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003ch2\u003eQ\u0026amp;A\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eWednesday 4:15-5:15pm\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch2\u003eTextbooks\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eJM3\u003c/strong\u003e: Jurafsky, Daniel S.; Martin, James H.; \u003ci\u003e\u003ca href=\"https://web.stanford.edu/~jurafsky/slp3/\"\u003eSpeech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition\u003c/a\u003e\u003c/i\u003e, Third Edition (incomplete draft)\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eE18\u003c/strong\u003e: Eisenstein, Jacob; \u003ca title=\"e18.pdf\" href=\"viewer/files/e18.pdf?canvas_download=1\" name=\"e18.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2586500\" data-api-returntype=\"File\"\u003e\u003ci\u003eNatural Language Processing\u003c/i\u003e\u003c/a\u003e, Draft textbook 15/10/18\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eG15\u003c/strong\u003e: Goldberg, Yoav; \u003ca title=\"g15.pdf\" href=\"viewer/files/g15.pdf?canvas_download=1\" name=\"g15.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2586501\" data-api-returntype=\"File\"\u003e\u003cem\u003eA Primer on Neural Network Models for Natural Language Processing\u003c/em\u003e\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 701px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDate\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eLecture\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eTitle\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eTopic\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eReadings\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e2 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e1\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL1\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l1-intro.pdf\" href=\"viewer/files/l1-intro.pdf?canvas_download=1\" name=\"l1-intro.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2662053\" data-api-returntype=\"File\"\u003eCourse Overview \u0026amp; Introduction\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eIntroduction\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eN/A\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL2\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l2-preprocessing.pdf\" href=\"viewer/files/l2-preprocessing.pdf?canvas_download=1\" name=\"l2-preprocessing.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2711847\" data-api-returntype=\"File\"\u003eText Preprocessing\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 2 on Normalisation\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e9 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e2\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL3\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l3-ngram.pdf\" href=\"viewer/files/l3-ngram.pdf?canvas_download=1\" name=\"l3-ngram.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2741206\" data-api-returntype=\"File\"\u003eN-gram Language Models\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eWords/Documents\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 6 (skip 6.3)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL4\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l4-text-classification.pdf\" href=\"viewer/files/l4-text-classification.pdf?canvas_download=1\" name=\"l4-text-classification.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2697669\" data-api-returntype=\"File\"\u003eText Classification\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\r\n\u003cdiv class=\"page\" title=\"Page 33\"\u003e\r\n\u003cdiv class=\"section\"\u003e\r\n\u003cdiv class=\"layoutArea\"\u003e\r\n\u003cdiv class=\"column\"\u003e\r\n\u003cp\u003e\u003cspan\u003eE18 Chapter 4.1, 4.3-4.4.1 \u003c/span\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e16 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e3\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL5\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l5-pos.pdf\" href=\"viewer/files/l5-pos.pdf?canvas_download=1\" name=\"l5-pos.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2769366\" data-api-returntype=\"File\"\u003ePart of Speech Tagging\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eSequence Labelling\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 8, 8.1-8.3, 8.5.1\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL6\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l6-hmm.pdf\" href=\"viewer/files/l6-hmm.pdf?canvas_download=1\" name=\"l6-hmm.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2733786\" data-api-returntype=\"File\"\u003eSequence Tagging: Hidden Markov Models\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Appendix A.1-A.2, A.4\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; text-align: center; height: 29px;\" colspan=\"6\"\u003e\u003cstrong\u003eSemester Pause (23 March - 27 March)\u003c/strong\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e30 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e4\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL7\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l7-feedforward.pdf\" href=\"viewer/files/l7-feedforward.pdf?canvas_download=1\" name=\"l7-feedforward.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2801273\" data-api-returntype=\"File\"\u003eDeep Learning for NLP: Feedforward Networks\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eDeep Learning\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eG15 Section 4, 9\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL8\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l8-recurrent.pdf\" href=\"viewer/files/l8-recurrent.pdf?canvas_download=1\" name=\"l8-recurrent.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2801275\" data-api-returntype=\"File\"\u003eDeep Learning for NLP: Recurrent Networks\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eG15 Section 10, 11\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; text-align: center; height: 29px;\" colspan=\"6\"\u003e\u003cstrong\u003eExtended Easter Break (6 April - 19 April)\u003c/strong\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 53px;\" rowspan=\"2\"\u003e20 April\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 53px;\" rowspan=\"2\"\u003e5\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 24px;\"\u003eL9\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 24px;\"\u003e\u003ca title=\"l9-lexical-semantics.pdf\" href=\"viewer/files/l9-lexical-semantics.pdf?canvas_download=1\" name=\"l9-lexical-semantics.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3098737\" data-api-returntype=\"File\"\u003eLexical Semantics\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"height: 111px; width: 12.5816%;\" rowspan=\"4\"\u003eSemantics\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 24px;\"\u003e\r\n\u003cp\u003e\u003cspan class=\"s2\"\u003eJM3 Chapter 19.1-19.3, 19.4.1, 19.5.1\u003c/span\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL10\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l10-distributional-semantics.pdf\" href=\"viewer/files/l10-distributional-semantics.pdf?canvas_download=1\" name=\"l10-distributional-semantics.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3098736\" data-api-returntype=\"File\"\u003eDistributional Semantics\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 6\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e27 April\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e6\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL11\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l11-contextual-representation.pdf\" href=\"viewer/files/l11-contextual-representation.pdf?canvas_download=1\" name=\"l11-contextual-representation.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181791\" data-api-returntype=\"File\"\u003eContextual Representation\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\r\n\u003cp\u003e\u003cspan class=\"s1\"\u003e\u003cspan class=\"s2\"\u003e\u003ca href=\"https://arxiv.org/abs/1802.05365v2,\" target=\"_blank\"\u003ehttps://arxiv.org/abs/1802.05365v2\u003c/a\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"s1\"\u003e \u003ca href=\"https://arxiv.org/abs/1810.04805\"\u003e\u003cspan class=\"s2\"\u003ehttps://arxiv.org/abs/1810.04805\u003c/span\u003e\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL12\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l12-discourse.pdf\" href=\"viewer/files/l12-discourse.pdf?canvas_download=1\" target=\"_blank\" name=\"l12-discourse.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181792\" data-api-returntype=\"File\"\u003eDiscourse\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 16\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e4 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e7\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL13\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l13-formal-language-theory.pdf\" href=\"viewer/files/l13-formal-language-theory.pdf?canvas_download=1\" target=\"_blank\" name=\"l13-formal-language-theory.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3388137\" data-api-returntype=\"File\"\u003eFormal Language Theory \u0026amp; Finite State Automata\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 116px;\" rowspan=\"4\"\u003eSyntax\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 9.1\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL14\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l14-context-free-grammar.pdf\" href=\"viewer/files/l14-context-free-grammar.pdf?canvas_download=1\" name=\"l14-context-free-grammar.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3355428\" data-api-returntype=\"File\"\u003eContext-Free Grammar\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 9.2, 10.1\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e11 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e8\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL15\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l15-probabilistic-cfg.pdf\" href=\"viewer/files/l15-probabilistic-cfg.pdf?canvas_download=1\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3439340\" data-api-returntype=\"File\"\u003eProbabilistic Context-Free Grammar\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 14-14.6 (skip 14.6.1)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL16\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l16-dependency.pdf\" href=\"viewer/files/l16-dependency.pdf?canvas_download=1\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3439341\" data-api-returntype=\"File\"\u003eDependency Grammar\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 15\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e18 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e9\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL17\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l17-machine-translation.pdf\" href=\"viewer/files/l17-machine-translation.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\"\u003eMachine Translation\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"height: 155px; width: 12.5816%;\" rowspan=\"6\"\u003eApplications\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\n\u003ca href=\"https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf\"\u003ehttps://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf\u003c/a\u003e (Section 1-5)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL18\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l18-information-extraction.pdf\" href=\"viewer/files/l18-information-extraction.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\"\u003eInformation Extraction\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 18-18.2\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px; text-align: center;\" rowspan=\"2\"\u003e25 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px; text-align: center;\" rowspan=\"2\"\u003e10\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px; text-align: center;\"\u003eL19\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px; text-align: center;\"\u003eQuestion Answering\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px; text-align: center;\"\u003eJM3 Chapter 25\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px; text-align: center;\"\u003eL20\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px; text-align: center;\"\u003eTopic Modelling\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 39px;\" rowspan=\"2\"\u003e1 June\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 39px;\" rowspan=\"2\"\u003e11\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 10px;\"\u003eL21\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 10px;\"\u003eSummarisation\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL22\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003eSubject Review\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"slides"},{"id":1905056,"title":"Neural Network Basics","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eFor those who are interested to learn more about neural network basics, I've shared some lecture slides and recordings from COMP90049 Introduction to Machine Learning:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eLecture 7: \u003ca title=\"7-1-optimization.pdf\" href=\"viewer/files/7-1-optimization.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"7-1-optimization.pdf\"\u003eiterative optimisation\u003c/a\u003e and \u003ca title=\"7-2-logisticregression.pdf\" href=\"viewer/files/7-2-logisticregression.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"7-2-logisticregression.pdf\"\u003elogistic regression\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eLecture 8: \u003ca title=\"8-perceptron.pdf\" href=\"viewer/files/8-perceptron.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"8-perceptron.pdf\"\u003eperceptron\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eLecture 9: \u003ca title=\"9-neural-nets.pdf\" href=\"viewer/files/9-neural-nets.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"9-neural-nets.pdf\"\u003emultilayer perceptron (aka neural networks)\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eLecture 10: \u003ca title=\"10-backprop_v3.pdf\" href=\"viewer/files/10-backprop_v3.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"10-backprop_v3.pdf\"\u003ebackpropagation\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eLecture recordings for these lectures can be found on the \"Lecture Capture\" tab (scroll down and expand \"\u003cspan\u003eCOMP90049 Introduction to Machine Learning\").\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eNone of these materials are examinable of course.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"neural-network-basics"}]},{"id":367221,"name":"Workshops","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g7240d2a1fd0f32ab11382740c64caec3","items":[{"id":1794699,"title":"Timetable","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003ctable style=\"border-collapse: collapse; width: 84.3682%; height: 483px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 62px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eAili Shen\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 62px; width: 40%;\" colspan=\"2\"\u003eSession 19 (12:00pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 62px; width: 40%;\" colspan=\"2\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 78px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 43px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eBiaoyan Fang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 43px;\" colspan=\"2\"\u003eSession 14 (5:15pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 43px;\" colspan=\"2\"\u003eSession 5 (11:00am Wed)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 63px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDalin Wang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 8 (6:15pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 1 (3:15pm Fri)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 63px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eFajri\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 13 (5:30pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 6 (10:00am Fri)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 64px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eHaonan Li\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 64px;\" colspan=\"2\"\u003eSession 18 (3:00pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 64px;\" colspan=\"2\"\u003eSession 10 (5:00pm Thu)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 67px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eJun Wang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 67px;\" colspan=\"2\"\u003eSession 1 (3:00pm Tue)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 67px;\" colspan=\"2\"\u003eSession 2 (3:00pm Wed)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 60px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eNitika Mathur\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 60px;\" colspan=\"2\"\u003eSession 17 (11:00am Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 60px;\" colspan=\"2\"\u003eSession 11 (4:00pm Tue)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 45px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 61px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eZenan Zhai\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 40%; text-align: center; height: 61px;\" colspan=\"2\"\u003eSession 3 (3:00pm Thu)\u003c/td\u003e\r\n\u003ctd style=\"width: 40%; text-align: center; height: 61px;\" colspan=\"2\"\u003eQ\u0026amp;A (4:15pm Fri)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"timetable"},{"id":1751841,"title":"Worksheets/Notebooks","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003ctable style=\"border-collapse: collapse; width: 86.9678%; height: 39px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDate\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWorksheets\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eNotebooks\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eSolutions\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.08989%; height: 10px;\" rowspan=\"2\"\u003e9 Mar\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; height: 10px;\" rowspan=\"2\"\u003e2\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; height: 10px; padding-left: 40px;\" rowspan=\"2\"\u003e\u003ca id=\"2688796\" class=\"instructure_file_link instructure_scribd_file\" title=\"workshop-02.pdf\" href=\"viewer/files/workshops/worksheets/workshop-02.pdf?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2688796\" data-api-returntype=\"File\"\u003eworkshop-02.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%; height: 10px;\" rowspan=\"2\"\u003e\r\n\u003cp\u003e\u003ca id=\"2688786\" class=\"instructure_file_link\" title=\"01-preprocessing.ipynb\" href=\"viewer/files/workshops/notebooks/01-preprocessing.ipynb?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"false\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2688786\" data-api-returntype=\"File\"\u003e01-preprocessing.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003ca id=\"2688787\" class=\"instructure_file_link\" title=\"02-bpe.ipynb\" href=\"viewer/files/workshops/notebooks/02-bpe.ipynb?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"false\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2701435\" data-api-returntype=\"File\"\u003e02-bpe.ipynb\u003c/a\u003e\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\" rowspan=\"2\"\u003e\r\n\u003cp\u003e\u003ca id=\"2688795\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-02.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2688795\" data-api-returntype=\"File\"\u003esolutions-02.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"2726166\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/02-bpe-solution.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726166\" data-api-returntype=\"File\"\u003e02-bpe-solution.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e16 March\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e3\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"2726163\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-03.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726163\" data-api-returntype=\"File\"\u003eworkshop-03.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2726159\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/03-classification.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726159\" data-api-returntype=\"File\"\u003e03-classification.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2726158\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/04-ngram.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726158\" data-api-returntype=\"File\"\u003e04-ngram.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2778041\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-03.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778041\" data-api-returntype=\"File\"\u003esolutions-03.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e23 March\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e4\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"2778066\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-04.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778066\" data-api-returntype=\"File\"\u003eworkshop-04.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2778062\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/05-pos-tagging.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778062\" data-api-returntype=\"File\"\u003e05-pos-tagging.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2778063\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/06-hmm.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778063\" data-api-returntype=\"File\"\u003e06-hmm.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2954615\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-04.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2954615\" data-api-returntype=\"File\"\u003esolutions-04.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e20 April\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e5\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"3082413\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-05.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082413\" data-api-returntype=\"File\"\u003eworkshop-05.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3082418\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/07-deep-learning.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082418\" data-api-returntype=\"File\"\u003e07-deep-learning.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3082417\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/notebooks/07-yelp-dataset.txt?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082417\" data-api-returntype=\"File\"\u003e07-yelp-dataset.txt\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-05.pdf?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082412\" data-api-returntype=\"File\"\u003esolutions-05.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e27 April\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e6\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-06.pdf?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181555\" data-api-returntype=\"File\"\u003eworkshop-06.pd\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca href=\"viewer/files/workshops/notebooks/08-lexical-semantics.ipynb?canvas_download=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181511\" data-api-returntype=\"File\"\u003e08-lexical-semantics.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca href=\"viewer/files/workshops/notebooks/09-distributional-semantics.ipynb?canvas_download=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181512\" data-api-returntype=\"File\"\u003e09-distributional-semantics.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334640\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-06.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334640\" data-api-returntype=\"File\"\u003esolutions-06.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e4 May\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e7\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"3334642\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-07.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334642\" data-api-returntype=\"File\"\u003eworkshop-07.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334624\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/10-bert.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334624\" data-api-returntype=\"File\"\u003e10-bert.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334674\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/10-dataset.zip?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334674\" data-api-returntype=\"File\"\u003e10-dataset.zip\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334641\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-07.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334641\" data-api-returntype=\"File\"\u003esolutions-07.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e11 May\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e8\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"3421360\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-08.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3421360\" data-api-returntype=\"File\"\u003eworkshop-08.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e-\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-08.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3421355\" data-api-returntype=\"File\"\u003esolutions-08.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e18 May\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e9\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-09.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3526950\" data-api-returntype=\"File\"\u003eworkshop-09.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e-\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e \u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"worksheets-slash-notebooks"},{"id":1768368,"title":"Workshop Slides","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e \u003c/p\u003e\r\n\u003ctable style=\"border-collapse: collapse; width: 93.7326%; height: 117px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 11.4415%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eJun Wang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(3:00pm Tue, 3:00pm Wed)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 4.6362%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eBiaoyan Fang\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(5:15pm Mon, 11:00AM Wed)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 5.52742%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eHaonan Li\u003c/strong\u003e\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(3:15pm Mon, 5:15pm Thu)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 5.36573%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eZenan Zhai\u003c/strong\u003e\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(3:00pm Thu, 3:00pm Fri)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.18352%; height: 58px;\" rowspan=\"2\"\u003e2\u003c/td\u003e\r\n\u003ctd style=\"width: 11.4415%; height: 58px; padding-left: 40px; text-align: center;\" rowspan=\"2\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop02-slides.pdf\" href=\"viewer/files/Uploaded%20Media/workshop02-slides.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2725977\" data-canvas-previewable=\"false\"\u003eworkshop02-slides.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 4.6362%; height: 58px;\" rowspan=\"2\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"COMP90042_Week_2.pdf\" href=\"viewer/files/Uploaded%20Media/COMP90042_Week_2.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2725165\" data-canvas-previewable=\"false\"\u003eCOMP90042_Week_2.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.52742%; height: 58px; text-align: center;\" rowspan=\"2\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop_slides_02.pdf\" href=\"viewer/files/Uploaded%20Media/workshop_slides_02.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2725882\" data-canvas-previewable=\"false\"\u003eworkshop_slides_02.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.36573%; height: 58px;\" rowspan=\"2\"\u003e\u003ca id=\"2726203\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/zenan/COMP90042_2020_Week2.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726203\" data-canvas-previewable=\"true\"\u003eCOMP90042_2020_Week2.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\u003c/tr\u003e\r\n\u003ctr style=\"height: 30px;\"\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center; height: 30px;\"\u003e3\u003c/td\u003e\r\n\u003ctd style=\"width: 11.4415%; padding-left: 40px; text-align: center; height: 30px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop03-slides.pdf\" href=\"viewer/files/Uploaded%20Media/workshop03-slides.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2776685\" data-canvas-previewable=\"false\"\u003eworkshop03-slides.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 4.6362%; height: 30px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"COMP90042_Week_3.pdf\" href=\"viewer/files/Uploaded%20Media/COMP90042_Week_3.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"false\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2783197\" data-api-returntype=\"File\"\u003eCOMP90042_Week_3.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.52742%; height: 30px; text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop_slides_03-3.pdf\" href=\"viewer/files/Uploaded%20Media/workshop_slides_03-3.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2780402\" data-canvas-previewable=\"false\"\u003eworkshop_slides_03.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.36573%; text-align: center; height: 30px;\"\u003e\u003ca id=\"2778070\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/zenan/COMP90042_2020_Week3.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778070\" data-canvas-previewable=\"true\"\u003eCOMP90042_2020_Week3.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e4\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center; width: 26.9708%;\" colspan=\"4\"\u003e\u003ca id=\"2954586\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week4.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2954586\" data-api-returntype=\"File\"\u003eWeek4.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e5\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center;\" colspan=\"3\"\u003e\u003ca id=\"3191368\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week5.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3191368\" data-api-returntype=\"File\"\u003eWeek5.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center; width: 5.36573%;\"\u003e\u003ca id=\"3191387\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week5_zz.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3191387\" data-api-returntype=\"File\"\u003eWeek5_zz.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e6\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center;\" colspan=\"4\"\u003e\u003ca id=\"3334680\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/notebooks/Week6.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334680\" data-api-returntype=\"File\"\u003eWeek6.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e7\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center;\" colspan=\"4\"\u003e\u003ca id=\"3421135\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week7.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3421135\" data-api-returntype=\"File\"\u003eWeek7.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e8\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center; width: 11.4415%;\" colspan=\"4\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week8_updated.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\"\u003eWeek8_updated.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"workshop-slides"},{"id":1772759,"title":"Recordings","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e \u003c/p\u003e\r\n\u003ctable style=\"border-collapse: collapse; width: 98.232%; height: 115px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 21px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eTutor\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.3928%; text-align: center; height: 21px;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eJun\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 21px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eZenan\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eAili\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eBiaoyan\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDalin\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eFajri\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eHaonan\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eNitika\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 10px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek2\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.3928%; text-align: center; height: 10px;\" colspan=\"2\"\u003e\r\n\u003cdiv\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/Edm0YqZPDXpFuuj73KG95pUBP2hlDNEEpfx4cx4nSFmzRw?e=j2FpNj\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/div\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 10px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EVdJ33Of45JMsmjI452VruwBDupjahelE8CF8LDJe4ORmQ?e=olqqZ4\" target=\"_blank\"\u003e3:00pm Fri\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 10px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 28px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek3\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 28px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EfzTzAWPDUBHnr6OvEQdY-UBA2oIJivjnHbmtL8IggD--g?e=2BmnPa\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 28px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EcnrnSU9wdhKikK3F919AOMBw8DqxSRvdwJfHqaPJze_-g?e=f7G1LE\" target=\"_blank\"\u003e3:00pm Fri\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 51px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 17px;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eWeek4\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 17px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EaFmryMxmIdClfavGZgUHGQB872hJFLgZIWIWhqFbxS2pg?e=2TktUL\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 17px; width: 12.3928%;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/ET7MZZ8oQmdGnlsz3w0qY_UBmVIpz7PPpekSO76A1Epq0Q?e=yiM2Ux\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e3:00pm Fri\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 17px;\"\u003e\r\n\u003ch4\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EfuhnxrhycdCqCzLS4yS-f4BVVI8Vzu6axxMse4V6j-sZA?e=jPEQxS\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e10.00am Fri\u003c/span\u003e\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 46px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 39px;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eWeek5\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 39px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EbTT1a-0y9xIs72OSKOuocUBdSbSbZ_EyP0fXtkEv7OlFw?e=qbiyjh\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 39px; width: 12.3928%;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EQnURyDkQ65FlF5PPw-p2U0B-t29WiWxMjdXejlNnTCesQ?e=FzK03o\" target=\"_blank\"\u003e3:00pm Thu\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 39px;\"\u003e\u003ca href=\"https://1drv.ms/u/s!AuOb2Ur-KnyRcSW1sOxqvgCzdRg?e=8U3mM6\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e12:00pm\u003c/span\u003e \u003cspan style=\"font-size: 14pt;\"\u003eMon\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 39px;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EVnXu7rKt4hIikCcpHy6Fb4Bh8KrH-RBGqRXeZwrSUiOaw?e=ZfXqee\" target=\"_blank\"\u003e5.30pm Mon\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eWeek6\u003c/strong\u003e\u003cstrong\u003e \u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; width: 12.3928%;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EbKDdh5M3QdDuiGCu43voUkBZ0p_UAIceX5WnqVHemQ2_Q?e=8SC2K5\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; width: 12.3928%;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EfcyR8WCLmBGoy3MNTyWsnsBNYhL1OEcC_VZ3iVP4-UiDg?e=LIsQzj\" target=\"_blank\"\u003e3:00pm Thu\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center;\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EfZJ-vil_MZFiZlf9Tc047cByy__qlN3pUMdjNU20y5Q0Q?e=ngwHRU\" target=\"_blank\"\u003e10.00am Fri\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek7\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EZBkKpGwqoxJtzCBX5-5M3YBxKlp4udb-r46_WD6etI90w?e=sn90lC\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e3:00pm Wed\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"text-align: center;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EVPzZ8WLWR1PutAm_ofkdwMBcv78z9q39XEjw_KMnfUPGg?e=e2QIXG\" target=\"_blank\"\u003e3:00pm Thu\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center;\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EZUCPh6BHsBHgunEAtxDIg0B-r6kPX3BEvgU8X_r2XUlng?e=3Rg0IR\" target=\"_blank\"\u003e10.00am Fri\u003c/a\u003e \u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek8\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.3928%; text-align: center;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EWeSQcZ7FoZHta9jlZn9O74BnurDpMAtl3YGzxAtsH9m0g?e=sOYjGS\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e 3:00pm Wed\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; width: 12.3928%;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/ERvm12CziHtHvFncdrQZB70B51rQzBpR0z5nM5v05CLXng?e=8yCIyQ\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e3:00pm Thu\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center;\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/ERv5Mz_DxdtJjAcT6GfpAbkBZfpQv0fHOJ2PU5pvsXK87w?e=Ia7jNY\" target=\"_blank\"\u003e5.30pm Mon\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"recordings"}]},{"id":367246,"name":"Academic Integrity","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g2aebe0c633add5d19faf466fbdad381d","items":[{"id":1678344,"title":"Academic Integrity Principles at Unimelb","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003ePlease have a read through the informational document regarding Academic Integrity at the University of Melbourne. If you are new to the University, you should take extra care, but even experienced students have been known to have mis-understandings about the policies.\u003c/p\u003e\r\n\u003cp\u003eEvery semester, there are a number of students who are compelled to appear in front of an Academic Honesty board. Although it is often the case that there was simply a mis-understanding of the expectations surrounding Academic Integrity, it is still a stressful experience. By familiarising yourself with the expectations in advance, you can hopefully save yourself from an unpleasant situation.\u003c/p\u003e\r\n\u003cp\u003eYou can read more about Academic Integrity, including definitions of plagiarism and collusion, and some useful links at the University's Academic Integrity site.\u003c/p\u003e","exportId":"academic-integrity-principles-at-unimelb"}]},{"id":367247,"name":"Resources","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g324b8e21482487cf5ee19fd928b10d5b","items":[{"id":1678430,"title":"Using Jupyter Notebook and Python","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eHere, we provide some resources for you to get set up with the required tools and programs, as well as brief tutorials on writing programs that load data, apply machine learning algorithms, and evaluate their output. Resources will be added \u0026amp; updated throughout the semester.\u003c/p\u003e\r\n\u003ch4\u003e \u003c/h4\u003e\r\n\u003ch4\u003e\u003cspan style=\"color: #111111; font-family: 'Open Sans', sans-serif; font-size: 18pt; font-style: normal; font-weight: 400; text-align: left; text-indent: 0px; white-space: normal; background-color: #ffffff; display: inline !important; float: none;\"\u003eInstalling Python and Jupyter Notebook\u003c/span\u003e\u003c/h4\u003e\r\n\u003cp\u003eJupyter Notebook runs a web app in the browser, and supports notebooks in Python (as well as many other languages).\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cspan style=\"font-size: 14pt;\"\u003eOn your machine\u003c/span\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eTo get \u003ca href=\"https://jupyter.org\" target=\"_blank\"\u003eJupyter Notebook\u003c/a\u003e and \u003ca href=\"https://www.python.org/\" target=\"_blank\"\u003ePython\u003c/a\u003e running on your personal machine, we recommend installing a Python distribution such as \u003ca href=\"https://www.anaconda.com/\" target=\"_blank\"\u003eAnaconda\u003c/a\u003e. If you use Linux, you can also use the Python packages provided through your distro. The way you install packages depends on your Python distribution. Some offer a package management GUI, others require you to use the command line (e.g. \u003cspan style=\"font-family: andale mono, times;\"\u003epip\u003c/span\u003e or \u003cspan style=\"font-family: andale mono, times;\"\u003econda\u003c/span\u003e).\u003c/p\u003e\r\n\u003cp\u003eAt a minimum, you'll need the following packages installed:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003enumpy\u003c/li\u003e\r\n\u003cli\u003esklearn\u003c/li\u003e\r\n\u003cli\u003ejupyter (\u003ca href=\"https://jupyter.org/install.html\" target=\"_blank\"\u003einstall guide\u003c/a\u003e)\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cspan style=\"font-size: 14pt;\"\u003eOn the university lab machines\u003c/span\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eOn the university lab/library machines, we recommend using the version of Jupyter Notebook provided by \u003ca style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: inherit; color: #1874a4; text-decoration: underline;\" title=\"Anaconda\" href=\"https://www.anaconda.com/\" target=\"_blank\"\u003eAnaconda\u003c/a\u003e (a Python distribution). To get this running, follow the steps below:\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: inherit; font-size: 13px; display: list-item; list-style-position: outside; list-style-type: inherit;\"\u003e\u003cspan style=\"font-size: 12pt;\"\u003eOpen the Start menu and select \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: italic;\"\u003eAnaconda3 (64-bit)\u003c/em\u003e -\u0026gt; \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: italic;\"\u003eAnaconda Prompt\u003c/em\u003e. A Command Prompt should pop up. This is different to a regular Command Prompt, as the path environment variable has been corrected to point to the Anaconda executables.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: inherit; font-size: 13px; display: list-item; list-style-position: outside; list-style-type: inherit;\"\u003e\n\u003cspan style=\"font-size: 12pt;\"\u003eStart Jupyter Notebook by entering the following command:\u003c/span\u003e\u003cbr style=\"font-family: 'Open Sans', sans-serif;\"\u003e\u003cspan style=\"font-family: 'andale mono', times; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: inherit; font-size: 12pt;\"\u003e\u0026gt; jupyter notebook\u003c/span\u003e\u003cbr style=\"font-family: 'Open Sans', sans-serif;\"\u003e\u003cspan style=\"font-size: 12pt;\"\u003ereplacing `\u0026lt;username\u0026gt;` with your central username. Jupyter Notebook should open in a browser window automatically. If not, you may need to enter the URL for the notebook server (typically \u003ca style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: inherit; color: #1874a4; text-decoration: underline;\" href=\"http://localhost:8888/\" target=\"_blank\"\u003ehttp://localhost:8888\u003c/a\u003e) into your browser manually.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: inherit; font-size: 13px; display: list-item; list-style-position: outside; list-style-type: inherit;\"\u003e\u003cspan style=\"font-size: 12pt;\"\u003eYou can now create new notebooks or open existing notebooks (.ipynb files). \u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003eNote\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eThere are several Python distributions installed on the lab machines. Some of them have Jupyter Notebook installed, however they may not have the packages we need and/or be an older version. If you encounter issues, please check that you're using the version provided by Anaconda3.\u003c/li\u003e\r\n\u003cli\u003eYou can also run Jupyter Notebook by selecting \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: italic; font-size: 13px;\"\u003eAnaconda3 (64-bit)\u003c/em\u003e -\u0026gt; \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: italic; font-size: 13px;\"\u003eJupyter Notebook\u003c/em\u003e from the Start menu. However, this does not allow you to change the working directory.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch4\u003e\u003cspan style=\"color: #111111; font-family: 'Open Sans', sans-serif; font-size: 18pt; font-style: normal; font-weight: 400; text-align: left; text-indent: 0px; white-space: normal; background-color: #ffffff; display: inline !important; float: none;\"\u003eJupyter Notebooks with example code for data processing, ML models, and evaluation\u003cbr\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003col\u003e\r\n\u003cli\u003e\u003cspan style=\"color: #111111; font-family: 'Open Sans', sans-serif; font-size: 12pt; font-style: normal; font-weight: 400; text-align: left; text-indent: 0px; white-space: normal; background-color: #ffffff; display: inline !important; float: none;\"\u003eA \u003ca id=\"2587984\" class=\"instructure_file_link\" href=\"viewer/files/demo_1.ipynb?canvas_download=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2587984\" data-api-returntype=\"File\"\u003eJupyter notebook\u003c/a\u003e for reading in and processing data sets from .csv files. And the \u003ca title=\"demo_1_data.csv\" href=\"viewer/files/demo_1_data.csv?canvas_download=1\" name=\"demo_1_data.csv\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2587983\" data-api-returntype=\"File\"\u003eaccompanying dataset\u003c/a\u003e.\u003cbr\u003e\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e","exportId":"using-jupyter-notebook-and-python"}]}],"pages":[{"exportId":"machine-learning-readings","title":"Machine Learning Readings","type":"WikiPage","content":"\u003cp\u003eThe subject assumes foundational knowledge of machine learning. The following readings are good sources on this topic:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eE18\u003c/strong\u003e: Eisenstein, Jacob; \u003ca title=\"e18.pdf\" href=\"viewer/files/e18.pdf?canvas_download=1\" name=\"e18.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2586500\" data-api-returntype=\"File\"\u003e\u003ci\u003eNatural Language Processing\u003c/i\u003e\u003c/a\u003e.\r\n\u003cul\u003e\r\n\u003cli\u003eProbability and optimisation: Appendix A \u0026amp; B\u003c/li\u003e\r\n\u003cli\u003eLinear classifiers: Chapter 2\u003c/li\u003e\r\n\u003cli\u003eNeural networks: Chapter 3\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e","frontPage":false},{"exportId":"recordings","title":"Recordings","type":"WikiPage","content":"\u003cp\u003e \u003c/p\u003e\r\n\u003ctable style=\"border-collapse: collapse; width: 98.232%; height: 115px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 21px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eTutor\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.3928%; text-align: center; height: 21px;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eJun\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 21px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eZenan\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eAili\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eBiaoyan\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDalin\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eFajri\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eHaonan\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 21px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eNitika\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 10px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek2\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.3928%; text-align: center; height: 10px;\" colspan=\"2\"\u003e\r\n\u003cdiv\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/Edm0YqZPDXpFuuj73KG95pUBP2hlDNEEpfx4cx4nSFmzRw?e=j2FpNj\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/div\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 10px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EVdJ33Of45JMsmjI452VruwBDupjahelE8CF8LDJe4ORmQ?e=olqqZ4\" target=\"_blank\"\u003e3:00pm Fri\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 10px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 28px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek3\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 28px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EfzTzAWPDUBHnr6OvEQdY-UBA2oIJivjnHbmtL8IggD--g?e=2BmnPa\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 28px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EcnrnSU9wdhKikK3F919AOMBw8DqxSRvdwJfHqaPJze_-g?e=f7G1LE\" target=\"_blank\"\u003e3:00pm Fri\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 28px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 51px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 17px;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eWeek4\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 17px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EaFmryMxmIdClfavGZgUHGQB872hJFLgZIWIWhqFbxS2pg?e=2TktUL\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 17px; width: 12.3928%;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/ET7MZZ8oQmdGnlsz3w0qY_UBmVIpz7PPpekSO76A1Epq0Q?e=yiM2Ux\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e3:00pm Fri\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 17px;\"\u003e\r\n\u003ch4\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EfuhnxrhycdCqCzLS4yS-f4BVVI8Vzu6axxMse4V6j-sZA?e=jPEQxS\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e10.00am Fri\u003c/span\u003e\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 17px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 46px;\"\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center; height: 39px;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eWeek5\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 39px; width: 12.3928%;\" colspan=\"2\"\u003e\r\n\u003ch4\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EbTT1a-0y9xIs72OSKOuocUBdSbSbZ_EyP0fXtkEv7OlFw?e=qbiyjh\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 39px; width: 12.3928%;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EQnURyDkQ65FlF5PPw-p2U0B-t29WiWxMjdXejlNnTCesQ?e=FzK03o\" target=\"_blank\"\u003e3:00pm Thu\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center; height: 39px;\"\u003e\u003ca href=\"https://1drv.ms/u/s!AuOb2Ur-KnyRcSW1sOxqvgCzdRg?e=8U3mM6\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e12:00pm\u003c/span\u003e \u003cspan style=\"font-size: 14pt;\"\u003eMon\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center; height: 39px;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EVnXu7rKt4hIikCcpHy6Fb4Bh8KrH-RBGqRXeZwrSUiOaw?e=ZfXqee\" target=\"_blank\"\u003e5.30pm Mon\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center; height: 39px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eWeek6\u003c/strong\u003e\u003cstrong\u003e \u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; width: 12.3928%;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EbKDdh5M3QdDuiGCu43voUkBZ0p_UAIceX5WnqVHemQ2_Q?e=8SC2K5\" target=\"_blank\"\u003e3:00pm Wed\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; width: 12.3928%;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EfcyR8WCLmBGoy3MNTyWsnsBNYhL1OEcC_VZ3iVP4-UiDg?e=LIsQzj\" target=\"_blank\"\u003e3:00pm Thu\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center;\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EfZJ-vil_MZFiZlf9Tc047cByy__qlN3pUMdjNU20y5Q0Q?e=ngwHRU\" target=\"_blank\"\u003e10.00am Fri\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek7\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EZBkKpGwqoxJtzCBX5-5M3YBxKlp4udb-r46_WD6etI90w?e=sn90lC\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e3:00pm Wed\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"text-align: center;\" colspan=\"2\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/EVPzZ8WLWR1PutAm_ofkdwMBcv78z9q39XEjw_KMnfUPGg?e=e2QIXG\" target=\"_blank\"\u003e3:00pm Thu\u003c/a\u003e\u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center;\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e\u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/EZUCPh6BHsBHgunEAtxDIg0B-r6kPX3BEvgU8X_r2XUlng?e=3Rg0IR\" target=\"_blank\"\u003e10.00am Fri\u003c/a\u003e \u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 1.60211%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek8\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.3928%; text-align: center;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/jun_wang9_unimelb_edu_au/EWeSQcZ7FoZHta9jlZn9O74BnurDpMAtl3YGzxAtsH9m0g?e=sOYjGS\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e 3:00pm Wed\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; width: 12.3928%;\" colspan=\"2\"\u003e\u003ca href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/zenan_zhai_unimelb_edu_au1/ERvm12CziHtHvFncdrQZB70B51rQzBpR0z5nM5v05CLXng?e=8yCIyQ\" target=\"_blank\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e3:00pm Thu\u003c/span\u003e\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 13.1967%; text-align: center;\"\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003c/span\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 10.8159%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 11.2551%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.6032%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cspan style=\"font-size: 14pt;\"\u003e \u003ca title=\"Link\" href=\"https://unimelbcloud-my.sharepoint.com/:v:/g/personal/f_fajri_unimelb_edu_au/ERv5Mz_DxdtJjAcT6GfpAbkBZfpQv0fHOJ2PU5pvsXK87w?e=Ia7jNY\" target=\"_blank\"\u003e5.30pm Mon\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.722%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 9.93684%; text-align: center;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false},{"exportId":"staff-information","title":"Staff information","type":"WikiPage","content":"\u003ch2\u003eSubject Co-ordinator\u003c/h2\u003e\r\n\u003cp\u003eJey Han Lau / \u003ca href=\"mailto:laujh@unimelb.edu.au\" target=\"_blank\"\u003elaujh@unimelb.edu.au\u003c/a\u003e\u003cem\u003e\u003cbr\u003e\u003c/em\u003e\u003c/p\u003e\r\n\u003cp\u003eOffice: Doug McDonell 3.25\u003c/p\u003e\r\n\u003cp\u003eOffice hours: by appointment\u003c/p\u003e\r\n\u003ch2\u003e \u003c/h2\u003e\r\n\u003ch2\u003eHead Tutor\u003c/h2\u003e\r\n\u003cp\u003eZenan Zhai / \u003ca href=\"mailto:zenanz@student.unimelb.edu.au\" target=\"_blank\"\u003ezenan.zhai@unimelb.edu.au\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2\u003e \u003c/h2\u003e\r\n\u003ch2\u003eSubject tutors\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eAili Shen / \u003ca href=\"mailto:aili.shen@unimelb.edu.au\" target=\"_blank\"\u003eailis@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eBiaoyan Fang / \u003ca href=\"mailto:biaoyanf@student.unimelb.edu.au\" target=\"_blank\"\u003ebiaoyan@unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eDalin Wang / \u003ca href=\"mailto:dalinw@student.unimelb.edu.au\" target=\"_blank\"\u003edalinw@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eFajri Koto / \u003ca href=\"mailto:ffajri@student.unimelb.edu.au\" target=\"_blank\"\u003efajrif@unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eHaonan Li / \u003ca href=\"mailto:haonanl5@student.unimelb.edu.au\" target=\"_blank\"\u003ehaonanl5@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eJun Wang / \u003ca href=\"mailto:jun5@unimelb.edu.au\" target=\"_blank\"\u003ejun5@unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eNitika Mathur / \u003ca href=\"mailto:nmathur@student.unimelb.edu.au\" target=\"_blank\"\u003enmathur@student.unimelb.edu.au\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false},{"exportId":"academic-integrity-principles-at-unimelb","title":"Academic Integrity Principles at Unimelb","type":"WikiPage","content":"\u003cp\u003ePlease have a read through the informational document regarding Academic Integrity at the University of Melbourne. If you are new to the University, you should take extra care, but even experienced students have been known to have mis-understandings about the policies.\u003c/p\u003e\r\n\u003cp\u003eEvery semester, there are a number of students who are compelled to appear in front of an Academic Honesty board. Although it is often the case that there was simply a mis-understanding of the expectations surrounding Academic Integrity, it is still a stressful experience. By familiarising yourself with the expectations in advance, you can hopefully save yourself from an unpleasant situation.\u003c/p\u003e\r\n\u003cp\u003eYou can read more about Academic Integrity, including definitions of plagiarism and collusion, and some useful links at the University's Academic Integrity site.\u003c/p\u003e","frontPage":false},{"exportId":"worksheets-slash-notebooks","title":"Worksheets/Notebooks","type":"WikiPage","content":"\u003ctable style=\"border-collapse: collapse; width: 86.9678%; height: 39px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDate\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWorksheets\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eNotebooks\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%; text-align: center;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eSolutions\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.08989%; height: 10px;\" rowspan=\"2\"\u003e9 Mar\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; height: 10px;\" rowspan=\"2\"\u003e2\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; height: 10px; padding-left: 40px;\" rowspan=\"2\"\u003e\u003ca id=\"2688796\" class=\"instructure_file_link instructure_scribd_file\" title=\"workshop-02.pdf\" href=\"viewer/files/workshops/worksheets/workshop-02.pdf?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2688796\" data-api-returntype=\"File\"\u003eworkshop-02.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%; height: 10px;\" rowspan=\"2\"\u003e\r\n\u003cp\u003e\u003ca id=\"2688786\" class=\"instructure_file_link\" title=\"01-preprocessing.ipynb\" href=\"viewer/files/workshops/notebooks/01-preprocessing.ipynb?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"false\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2688786\" data-api-returntype=\"File\"\u003e01-preprocessing.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003ca id=\"2688787\" class=\"instructure_file_link\" title=\"02-bpe.ipynb\" href=\"viewer/files/workshops/notebooks/02-bpe.ipynb?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"false\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2701435\" data-api-returntype=\"File\"\u003e02-bpe.ipynb\u003c/a\u003e\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\" rowspan=\"2\"\u003e\r\n\u003cp\u003e\u003ca id=\"2688795\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-02.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2688795\" data-api-returntype=\"File\"\u003esolutions-02.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"2726166\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/02-bpe-solution.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726166\" data-api-returntype=\"File\"\u003e02-bpe-solution.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e16 March\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e3\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"2726163\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-03.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726163\" data-api-returntype=\"File\"\u003eworkshop-03.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2726159\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/03-classification.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726159\" data-api-returntype=\"File\"\u003e03-classification.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2726158\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/04-ngram.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726158\" data-api-returntype=\"File\"\u003e04-ngram.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2778041\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-03.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778041\" data-api-returntype=\"File\"\u003esolutions-03.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e23 March\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e4\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"2778066\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-04.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778066\" data-api-returntype=\"File\"\u003eworkshop-04.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2778062\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/05-pos-tagging.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778062\" data-api-returntype=\"File\"\u003e05-pos-tagging.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2778063\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/06-hmm.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778063\" data-api-returntype=\"File\"\u003e06-hmm.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"2954615\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-04.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2954615\" data-api-returntype=\"File\"\u003esolutions-04.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e20 April\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e5\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"3082413\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-05.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082413\" data-api-returntype=\"File\"\u003eworkshop-05.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3082418\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/07-deep-learning.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082418\" data-api-returntype=\"File\"\u003e07-deep-learning.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3082417\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/notebooks/07-yelp-dataset.txt?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082417\" data-api-returntype=\"File\"\u003e07-yelp-dataset.txt\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-05.pdf?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3082412\" data-api-returntype=\"File\"\u003esolutions-05.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e27 April\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e6\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-06.pdf?canvas_download=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181555\" data-api-returntype=\"File\"\u003eworkshop-06.pd\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca href=\"viewer/files/workshops/notebooks/08-lexical-semantics.ipynb?canvas_download=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181511\" data-api-returntype=\"File\"\u003e08-lexical-semantics.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca href=\"viewer/files/workshops/notebooks/09-distributional-semantics.ipynb?canvas_download=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181512\" data-api-returntype=\"File\"\u003e09-distributional-semantics.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334640\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-06.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334640\" data-api-returntype=\"File\"\u003esolutions-06.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e4 May\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e7\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"3334642\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-07.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334642\" data-api-returntype=\"File\"\u003eworkshop-07.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334624\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/10-bert.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334624\" data-api-returntype=\"File\"\u003e10-bert.ipynb\u003c/a\u003e\u003c/p\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334674\" class=\"instructure_file_link\" title=\"Link\" href=\"viewer/files/workshops/notebooks/10-dataset.zip?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334674\" data-api-returntype=\"File\"\u003e10-dataset.zip\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca id=\"3334641\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-07.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334641\" data-api-returntype=\"File\"\u003esolutions-07.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e11 May\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e8\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca id=\"3421360\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-08.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3421360\" data-api-returntype=\"File\"\u003eworkshop-08.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e-\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/solutions-08.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3421355\" data-api-returntype=\"File\"\u003esolutions-08.pdf\u003c/a\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.08989%; text-align: center;\"\u003e18 May\u003c/td\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e9\u003c/td\u003e\r\n\u003ctd style=\"width: 7.78623%; padding-left: 40px; text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/worksheets/workshop-09.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3526950\" data-api-returntype=\"File\"\u003eworkshop-09.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 8.38529%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e-\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 10.5054%;\"\u003e\r\n\u003cp style=\"text-align: center;\"\u003e \u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false},{"exportId":"timetable","title":"Timetable","type":"WikiPage","content":"\u003ctable style=\"border-collapse: collapse; width: 84.3682%; height: 483px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 62px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eAili Shen\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 62px; width: 40%;\" colspan=\"2\"\u003eSession 19 (12:00pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 62px; width: 40%;\" colspan=\"2\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 78px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 43px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eBiaoyan Fang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 43px;\" colspan=\"2\"\u003eSession 14 (5:15pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 43px;\" colspan=\"2\"\u003eSession 5 (11:00am Wed)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 63px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDalin Wang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 8 (6:15pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 1 (3:15pm Fri)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 63px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eFajri\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 13 (5:30pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 63px;\" colspan=\"2\"\u003eSession 6 (10:00am Fri)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 64px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eHaonan Li\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 64px;\" colspan=\"2\"\u003eSession 18 (3:00pm Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 64px;\" colspan=\"2\"\u003eSession 10 (5:00pm Thu)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 67px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eJun Wang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 67px;\" colspan=\"2\"\u003eSession 1 (3:00pm Tue)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 67px;\" colspan=\"2\"\u003eSession 2 (3:00pm Wed)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 44px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 60px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eNitika Mathur\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 60px;\" colspan=\"2\"\u003eSession 17 (11:00am Mon)\u003c/td\u003e\r\n\u003ctd style=\"text-align: center; height: 60px;\" colspan=\"2\"\u003eSession 11 (4:00pm Tue)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 45px;\"\u003e\r\n\u003ctd style=\"width: 20%; text-align: center; height: 61px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eZenan Zhai\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 40%; text-align: center; height: 61px;\" colspan=\"2\"\u003eSession 3 (3:00pm Thu)\u003c/td\u003e\r\n\u003ctd style=\"width: 40%; text-align: center; height: 61px;\" colspan=\"2\"\u003eQ\u0026amp;A (4:15pm Fri)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false},{"exportId":"slides","title":"Slides","type":"WikiPage","content":"\u003ch2\u003eQ\u0026amp;A\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eWednesday 4:15-5:15pm\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch2\u003eTextbooks\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eJM3\u003c/strong\u003e: Jurafsky, Daniel S.; Martin, James H.; \u003ci\u003e\u003ca href=\"https://web.stanford.edu/~jurafsky/slp3/\"\u003eSpeech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition\u003c/a\u003e\u003c/i\u003e, Third Edition (incomplete draft)\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eE18\u003c/strong\u003e: Eisenstein, Jacob; \u003ca title=\"e18.pdf\" href=\"viewer/files/e18.pdf?canvas_download=1\" name=\"e18.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2586500\" data-api-returntype=\"File\"\u003e\u003ci\u003eNatural Language Processing\u003c/i\u003e\u003c/a\u003e, Draft textbook 15/10/18\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eG15\u003c/strong\u003e: Goldberg, Yoav; \u003ca title=\"g15.pdf\" href=\"viewer/files/g15.pdf?canvas_download=1\" name=\"g15.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2586501\" data-api-returntype=\"File\"\u003e\u003cem\u003eA Primer on Neural Network Models for Natural Language Processing\u003c/em\u003e\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 701px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eDate\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eLecture\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eTitle\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eTopic\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eReadings\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e2 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e1\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL1\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l1-intro.pdf\" href=\"viewer/files/l1-intro.pdf?canvas_download=1\" name=\"l1-intro.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2662053\" data-api-returntype=\"File\"\u003eCourse Overview \u0026amp; Introduction\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eIntroduction\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eN/A\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL2\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l2-preprocessing.pdf\" href=\"viewer/files/l2-preprocessing.pdf?canvas_download=1\" name=\"l2-preprocessing.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2711847\" data-api-returntype=\"File\"\u003eText Preprocessing\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 2 on Normalisation\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e9 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e2\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL3\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l3-ngram.pdf\" href=\"viewer/files/l3-ngram.pdf?canvas_download=1\" name=\"l3-ngram.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2741206\" data-api-returntype=\"File\"\u003eN-gram Language Models\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eWords/Documents\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 6 (skip 6.3)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL4\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l4-text-classification.pdf\" href=\"viewer/files/l4-text-classification.pdf?canvas_download=1\" name=\"l4-text-classification.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2697669\" data-api-returntype=\"File\"\u003eText Classification\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\r\n\u003cdiv class=\"page\" title=\"Page 33\"\u003e\r\n\u003cdiv class=\"section\"\u003e\r\n\u003cdiv class=\"layoutArea\"\u003e\r\n\u003cdiv class=\"column\"\u003e\r\n\u003cp\u003e\u003cspan\u003eE18 Chapter 4.1, 4.3-4.4.1 \u003c/span\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e16 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e3\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL5\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l5-pos.pdf\" href=\"viewer/files/l5-pos.pdf?canvas_download=1\" name=\"l5-pos.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2769366\" data-api-returntype=\"File\"\u003ePart of Speech Tagging\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eSequence Labelling\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 8, 8.1-8.3, 8.5.1\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL6\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l6-hmm.pdf\" href=\"viewer/files/l6-hmm.pdf?canvas_download=1\" name=\"l6-hmm.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2733786\" data-api-returntype=\"File\"\u003eSequence Tagging: Hidden Markov Models\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Appendix A.1-A.2, A.4\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; text-align: center; height: 29px;\" colspan=\"6\"\u003e\u003cstrong\u003eSemester Pause (23 March - 27 March)\u003c/strong\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e30 March\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e4\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL7\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l7-feedforward.pdf\" href=\"viewer/files/l7-feedforward.pdf?canvas_download=1\" name=\"l7-feedforward.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2801273\" data-api-returntype=\"File\"\u003eDeep Learning for NLP: Feedforward Networks\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 58px;\" rowspan=\"2\"\u003eDeep Learning\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eG15 Section 4, 9\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL8\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l8-recurrent.pdf\" href=\"viewer/files/l8-recurrent.pdf?canvas_download=1\" name=\"l8-recurrent.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2801275\" data-api-returntype=\"File\"\u003eDeep Learning for NLP: Recurrent Networks\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eG15 Section 10, 11\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; text-align: center; height: 29px;\" colspan=\"6\"\u003e\u003cstrong\u003eExtended Easter Break (6 April - 19 April)\u003c/strong\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 53px;\" rowspan=\"2\"\u003e20 April\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 53px;\" rowspan=\"2\"\u003e5\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 24px;\"\u003eL9\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 24px;\"\u003e\u003ca title=\"l9-lexical-semantics.pdf\" href=\"viewer/files/l9-lexical-semantics.pdf?canvas_download=1\" name=\"l9-lexical-semantics.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3098737\" data-api-returntype=\"File\"\u003eLexical Semantics\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"height: 111px; width: 12.5816%;\" rowspan=\"4\"\u003eSemantics\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 24px;\"\u003e\r\n\u003cp\u003e\u003cspan class=\"s2\"\u003eJM3 Chapter 19.1-19.3, 19.4.1, 19.5.1\u003c/span\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL10\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l10-distributional-semantics.pdf\" href=\"viewer/files/l10-distributional-semantics.pdf?canvas_download=1\" name=\"l10-distributional-semantics.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3098736\" data-api-returntype=\"File\"\u003eDistributional Semantics\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 6\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e27 April\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e6\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL11\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l11-contextual-representation.pdf\" href=\"viewer/files/l11-contextual-representation.pdf?canvas_download=1\" name=\"l11-contextual-representation.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181791\" data-api-returntype=\"File\"\u003eContextual Representation\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\r\n\u003cp\u003e\u003cspan class=\"s1\"\u003e\u003cspan class=\"s2\"\u003e\u003ca href=\"https://arxiv.org/abs/1802.05365v2,\" target=\"_blank\"\u003ehttps://arxiv.org/abs/1802.05365v2\u003c/a\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"s1\"\u003e \u003ca href=\"https://arxiv.org/abs/1810.04805\"\u003e\u003cspan class=\"s2\"\u003ehttps://arxiv.org/abs/1810.04805\u003c/span\u003e\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL12\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l12-discourse.pdf\" href=\"viewer/files/l12-discourse.pdf?canvas_download=1\" target=\"_blank\" name=\"l12-discourse.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3181792\" data-api-returntype=\"File\"\u003eDiscourse\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 16\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e4 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e7\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL13\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l13-formal-language-theory.pdf\" href=\"viewer/files/l13-formal-language-theory.pdf?canvas_download=1\" target=\"_blank\" name=\"l13-formal-language-theory.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3388137\" data-api-returntype=\"File\"\u003eFormal Language Theory \u0026amp; Finite State Automata\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 12.5816%; height: 116px;\" rowspan=\"4\"\u003eSyntax\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 9.1\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL14\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l14-context-free-grammar.pdf\" href=\"viewer/files/l14-context-free-grammar.pdf?canvas_download=1\" name=\"l14-context-free-grammar.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3355428\" data-api-returntype=\"File\"\u003eContext-Free Grammar\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eE18 Chapter 9.2, 10.1\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e11 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e8\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL15\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l15-probabilistic-cfg.pdf\" href=\"viewer/files/l15-probabilistic-cfg.pdf?canvas_download=1\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3439340\" data-api-returntype=\"File\"\u003eProbabilistic Context-Free Grammar\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 14-14.6 (skip 14.6.1)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL16\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l16-dependency.pdf\" href=\"viewer/files/l16-dependency.pdf?canvas_download=1\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3439341\" data-api-returntype=\"File\"\u003eDependency Grammar\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 15\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px;\" rowspan=\"2\"\u003e18 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px;\" rowspan=\"2\"\u003e9\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL17\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l17-machine-translation.pdf\" href=\"viewer/files/l17-machine-translation.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\"\u003eMachine Translation\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"height: 155px; width: 12.5816%;\" rowspan=\"6\"\u003eApplications\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\n\u003ca href=\"https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf\"\u003ehttps://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf\u003c/a\u003e (Section 1-5)\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL18\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003e\u003ca title=\"l18-information-extraction.pdf\" href=\"viewer/files/l18-information-extraction.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\"\u003eInformation Extraction\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003eJM3 Chapter 18-18.2\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 58px; text-align: center;\" rowspan=\"2\"\u003e25 May\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 58px; text-align: center;\" rowspan=\"2\"\u003e10\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px; text-align: center;\"\u003eL19\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px; text-align: center;\"\u003eQuestion Answering\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px; text-align: center;\"\u003eJM3 Chapter 25\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px; text-align: center;\"\u003eL20\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px; text-align: center;\"\u003eTopic Modelling\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10px;\"\u003e\r\n\u003ctd style=\"width: 8.44055%; height: 39px;\" rowspan=\"2\"\u003e1 June\u003c/td\u003e\r\n\u003ctd style=\"width: 6.31859%; height: 39px;\" rowspan=\"2\"\u003e11\u003c/td\u003e\r\n\u003ctd style=\"width: 6.402%; height: 10px;\"\u003eL21\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 10px;\"\u003eSummarisation\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 10px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 29px;\"\u003e\r\n\u003ctd style=\"width: 6.402%; height: 29px;\"\u003eL22\u003c/td\u003e\r\n\u003ctd style=\"width: 33.3333%; height: 29px;\"\u003eSubject Review\u003c/td\u003e\r\n\u003ctd style=\"width: 21.969%; height: 29px;\"\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false},{"exportId":"workshop-slides","title":"Workshop Slides","type":"WikiPage","content":"\u003cp\u003e \u003c/p\u003e\r\n\u003ctable style=\"border-collapse: collapse; width: 93.7326%; height: 117px; margin-left: auto; margin-right: auto;\" border=\"2\"\u003e\r\n\u003ctbody\u003e\r\n\u003ctr style=\"height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eWeek\u003c/strong\u003e\u003c/h4\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 11.4415%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eJun Wang\u003c/strong\u003e\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(3:00pm Tue, 3:00pm Wed)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 4.6362%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\n\u003cstrong\u003eBiaoyan Fang\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\n\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(5:15pm Mon, 11:00AM Wed)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 5.52742%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eHaonan Li\u003c/strong\u003e\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(3:15pm Mon, 5:15pm Thu)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"width: 5.36573%; text-align: center; height: 29px;\"\u003e\r\n\u003ch4\u003e\u003cstrong\u003eZenan Zhai\u003c/strong\u003e\u003c/h4\u003e\r\n\u003cp\u003e\u003cstrong\u003e(3:00pm Thu, 3:00pm Fri)\u003c/strong\u003e\u003c/p\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr style=\"text-align: center; height: 10pt;\"\u003e\r\n\u003ctd style=\"width: 3.18352%; height: 58px;\" rowspan=\"2\"\u003e2\u003c/td\u003e\r\n\u003ctd style=\"width: 11.4415%; height: 58px; padding-left: 40px; text-align: center;\" rowspan=\"2\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop02-slides.pdf\" href=\"viewer/files/Uploaded%20Media/workshop02-slides.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2725977\" data-canvas-previewable=\"false\"\u003eworkshop02-slides.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 4.6362%; height: 58px;\" rowspan=\"2\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"COMP90042_Week_2.pdf\" href=\"viewer/files/Uploaded%20Media/COMP90042_Week_2.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2725165\" data-canvas-previewable=\"false\"\u003eCOMP90042_Week_2.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.52742%; height: 58px; text-align: center;\" rowspan=\"2\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop_slides_02.pdf\" href=\"viewer/files/Uploaded%20Media/workshop_slides_02.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2725882\" data-canvas-previewable=\"false\"\u003eworkshop_slides_02.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.36573%; height: 58px;\" rowspan=\"2\"\u003e\u003ca id=\"2726203\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/zenan/COMP90042_2020_Week2.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2726203\" data-canvas-previewable=\"true\"\u003eCOMP90042_2020_Week2.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\u003c/tr\u003e\r\n\u003ctr style=\"height: 30px;\"\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center; height: 30px;\"\u003e3\u003c/td\u003e\r\n\u003ctd style=\"width: 11.4415%; padding-left: 40px; text-align: center; height: 30px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop03-slides.pdf\" href=\"viewer/files/Uploaded%20Media/workshop03-slides.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2776685\" data-canvas-previewable=\"false\"\u003eworkshop03-slides.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 4.6362%; height: 30px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"COMP90042_Week_3.pdf\" href=\"viewer/files/Uploaded%20Media/COMP90042_Week_3.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"false\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2783197\" data-api-returntype=\"File\"\u003eCOMP90042_Week_3.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.52742%; height: 30px; text-align: center;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"workshop_slides_03-3.pdf\" href=\"viewer/files/Uploaded%20Media/workshop_slides_03-3.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2780402\" data-canvas-previewable=\"false\"\u003eworkshop_slides_03.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"width: 5.36573%; text-align: center; height: 30px;\"\u003e\u003ca id=\"2778070\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/zenan/COMP90042_2020_Week3.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-returntype=\"File\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2778070\" data-canvas-previewable=\"true\"\u003eCOMP90042_2020_Week3.pdf\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e4\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center; width: 26.9708%;\" colspan=\"4\"\u003e\u003ca id=\"2954586\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week4.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2954586\" data-api-returntype=\"File\"\u003eWeek4.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e5\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center;\" colspan=\"3\"\u003e\u003ca id=\"3191368\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week5.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3191368\" data-api-returntype=\"File\"\u003eWeek5.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center; width: 5.36573%;\"\u003e\u003ca id=\"3191387\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week5_zz.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3191387\" data-api-returntype=\"File\"\u003eWeek5_zz.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e6\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center;\" colspan=\"4\"\u003e\u003ca id=\"3334680\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/notebooks/Week6.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3334680\" data-api-returntype=\"File\"\u003eWeek6.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e7\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center;\" colspan=\"4\"\u003e\u003ca id=\"3421135\" class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week7.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/3421135\" data-api-returntype=\"File\"\u003eWeek7.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 3.18352%; text-align: center;\"\u003e8\u003c/td\u003e\r\n\u003ctd style=\"padding-left: 40px; text-align: center; width: 11.4415%;\" colspan=\"4\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Link\" href=\"viewer/files/workshops/slides/Week8_updated.pptx?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-canvas-previewable=\"true\"\u003eWeek8_updated.pptx\u003c/a\u003e\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false},{"exportId":"using-jupyter-notebook-and-python","title":"Using Jupyter Notebook and Python","type":"WikiPage","content":"\u003cp\u003eHere, we provide some resources for you to get set up with the required tools and programs, as well as brief tutorials on writing programs that load data, apply machine learning algorithms, and evaluate their output. Resources will be added \u0026amp; updated throughout the semester.\u003c/p\u003e\r\n\u003ch4\u003e \u003c/h4\u003e\r\n\u003ch4\u003e\u003cspan style=\"color: #111111; font-family: 'Open Sans', sans-serif; font-size: 18pt; font-style: normal; font-weight: 400; text-align: left; text-indent: 0px; white-space: normal; background-color: #ffffff; display: inline !important; float: none;\"\u003eInstalling Python and Jupyter Notebook\u003c/span\u003e\u003c/h4\u003e\r\n\u003cp\u003eJupyter Notebook runs a web app in the browser, and supports notebooks in Python (as well as many other languages).\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cspan style=\"font-size: 14pt;\"\u003eOn your machine\u003c/span\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eTo get \u003ca href=\"https://jupyter.org\" target=\"_blank\"\u003eJupyter Notebook\u003c/a\u003e and \u003ca href=\"https://www.python.org/\" target=\"_blank\"\u003ePython\u003c/a\u003e running on your personal machine, we recommend installing a Python distribution such as \u003ca href=\"https://www.anaconda.com/\" target=\"_blank\"\u003eAnaconda\u003c/a\u003e. If you use Linux, you can also use the Python packages provided through your distro. The way you install packages depends on your Python distribution. Some offer a package management GUI, others require you to use the command line (e.g. \u003cspan style=\"font-family: andale mono, times;\"\u003epip\u003c/span\u003e or \u003cspan style=\"font-family: andale mono, times;\"\u003econda\u003c/span\u003e).\u003c/p\u003e\r\n\u003cp\u003eAt a minimum, you'll need the following packages installed:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003enumpy\u003c/li\u003e\r\n\u003cli\u003esklearn\u003c/li\u003e\r\n\u003cli\u003ejupyter (\u003ca href=\"https://jupyter.org/install.html\" target=\"_blank\"\u003einstall guide\u003c/a\u003e)\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cspan style=\"font-size: 14pt;\"\u003eOn the university lab machines\u003c/span\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eOn the university lab/library machines, we recommend using the version of Jupyter Notebook provided by \u003ca style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: inherit; color: #1874a4; text-decoration: underline;\" title=\"Anaconda\" href=\"https://www.anaconda.com/\" target=\"_blank\"\u003eAnaconda\u003c/a\u003e (a Python distribution). To get this running, follow the steps below:\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: inherit; font-size: 13px; display: list-item; list-style-position: outside; list-style-type: inherit;\"\u003e\u003cspan style=\"font-size: 12pt;\"\u003eOpen the Start menu and select \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: italic;\"\u003eAnaconda3 (64-bit)\u003c/em\u003e -\u0026gt; \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: italic;\"\u003eAnaconda Prompt\u003c/em\u003e. A Command Prompt should pop up. This is different to a regular Command Prompt, as the path environment variable has been corrected to point to the Anaconda executables.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: inherit; font-size: 13px; display: list-item; list-style-position: outside; list-style-type: inherit;\"\u003e\n\u003cspan style=\"font-size: 12pt;\"\u003eStart Jupyter Notebook by entering the following command:\u003c/span\u003e\u003cbr style=\"font-family: 'Open Sans', sans-serif;\"\u003e\u003cspan style=\"font-family: 'andale mono', times; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: inherit; font-size: 12pt;\"\u003e\u0026gt; jupyter notebook\u003c/span\u003e\u003cbr style=\"font-family: 'Open Sans', sans-serif;\"\u003e\u003cspan style=\"font-size: 12pt;\"\u003ereplacing `\u0026lt;username\u0026gt;` with your central username. Jupyter Notebook should open in a browser window automatically. If not, you may need to enter the URL for the notebook server (typically \u003ca style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px none; font-weight: inherit; font-style: inherit; color: #1874a4; text-decoration: underline;\" href=\"http://localhost:8888/\" target=\"_blank\"\u003ehttp://localhost:8888\u003c/a\u003e) into your browser manually.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: inherit; font-size: 13px; display: list-item; list-style-position: outside; list-style-type: inherit;\"\u003e\u003cspan style=\"font-size: 12pt;\"\u003eYou can now create new notebooks or open existing notebooks (.ipynb files). \u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003eNote\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eThere are several Python distributions installed on the lab machines. Some of them have Jupyter Notebook installed, however they may not have the packages we need and/or be an older version. If you encounter issues, please check that you're using the version provided by Anaconda3.\u003c/li\u003e\r\n\u003cli\u003eYou can also run Jupyter Notebook by selecting \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: italic; font-size: 13px;\"\u003eAnaconda3 (64-bit)\u003c/em\u003e -\u0026gt; \u003cem style=\"font-family: inherit; margin: 0px; padding: 0px; border: 0px; font-weight: inherit; font-style: italic; font-size: 13px;\"\u003eJupyter Notebook\u003c/em\u003e from the Start menu. However, this does not allow you to change the working directory.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch4\u003e\u003cspan style=\"color: #111111; font-family: 'Open Sans', sans-serif; font-size: 18pt; font-style: normal; font-weight: 400; text-align: left; text-indent: 0px; white-space: normal; background-color: #ffffff; display: inline !important; float: none;\"\u003eJupyter Notebooks with example code for data processing, ML models, and evaluation\u003cbr\u003e\u003c/span\u003e\u003c/h4\u003e\r\n\u003col\u003e\r\n\u003cli\u003e\u003cspan style=\"color: #111111; font-family: 'Open Sans', sans-serif; font-size: 12pt; font-style: normal; font-weight: 400; text-align: left; text-indent: 0px; white-space: normal; background-color: #ffffff; display: inline !important; float: none;\"\u003eA \u003ca id=\"2587984\" class=\"instructure_file_link\" href=\"viewer/files/demo_1.ipynb?canvas_download=1\" target=\"_blank\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2587984\" data-api-returntype=\"File\"\u003eJupyter notebook\u003c/a\u003e for reading in and processing data sets from .csv files. And the \u003ca title=\"demo_1_data.csv\" href=\"viewer/files/demo_1_data.csv?canvas_download=1\" name=\"demo_1_data.csv\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2587983\" data-api-returntype=\"File\"\u003eaccompanying dataset\u003c/a\u003e.\u003cbr\u003e\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e","frontPage":false},{"exportId":"neural-network-basics","title":"Neural Network Basics","type":"WikiPage","content":"\u003cp\u003eFor those who are interested to learn more about neural network basics, I've shared some lecture slides and recordings from COMP90049 Introduction to Machine Learning:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eLecture 7: \u003ca title=\"7-1-optimization.pdf\" href=\"viewer/files/7-1-optimization.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"7-1-optimization.pdf\"\u003eiterative optimisation\u003c/a\u003e and \u003ca title=\"7-2-logisticregression.pdf\" href=\"viewer/files/7-2-logisticregression.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"7-2-logisticregression.pdf\"\u003elogistic regression\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eLecture 8: \u003ca title=\"8-perceptron.pdf\" href=\"viewer/files/8-perceptron.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"8-perceptron.pdf\"\u003eperceptron\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eLecture 9: \u003ca title=\"9-neural-nets.pdf\" href=\"viewer/files/9-neural-nets.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"9-neural-nets.pdf\"\u003emultilayer perceptron (aka neural networks)\u003c/a\u003e\n\u003c/li\u003e\r\n\u003cli\u003eLecture 10: \u003ca title=\"10-backprop_v3.pdf\" href=\"viewer/files/10-backprop_v3.pdf?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"10-backprop_v3.pdf\"\u003ebackpropagation\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eLecture recordings for these lectures can be found on the \"Lecture Capture\" tab (scroll down and expand \"\u003cspan\u003eCOMP90049 Introduction to Machine Learning\").\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eNone of these materials are examinable of course.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","frontPage":false}],"assignments":[{"exportId":"g942f0977785fb877caa1c923fbfdb788","title":"Assignment 1 - Text Preprocessing and Classification","type":"Assignment","content":"\u003cp\u003e\u003cspan\u003eIn this homework, you'll be working with a collection tweets. The task is to classify whether a tweet constitutes a rumour event. This homework involves writing code to preprocess data and perform text classification. This is an \u003cstrong\u003eindividual\u003c/strong\u003e assignment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eDownload the \u003ca id=\"2794974\" class=\"instructure_file_link\" href=\"viewer/files/01-assignment.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003ejupyter notebook\u003c/a\u003e and follow the instructions to complete the assignment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eThe submission deadline is \u003cstrong\u003eSunday, 5 Apr 2020, 5pm\u003c/strong\u003e. Please submit the completed notebook via Canvas. \u003cstrong\u003eImportant: Remember to write your name and student ID in the notebook.\u003c/strong\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003ePlease feel free to ask any questions about the assignment on the discussion board (without revealing your answers, of course). You can also email me if there are further questions.\u003c/span\u003e\u003c/p\u003e","submissionTypes":"a file upload","graded":true,"pointsPossible":10.0,"dueAt":"2020-04-05T17:00:00+10:00","lockAt":null,"unlockAt":null},{"exportId":"gb9541bc0aa2c19e3c460af99dad4009d","title":"Assignment 2 - Word Similarity","type":"Assignment","content":"\u003cp\u003e\u003cspan\u003eIn this homework, you'll be quantifying the similarity between pairs of words of a dataset using different methods with the word co-occurrence in the Brown corpus and synset structure of WordNet. Firstly, you will preprocess the dataset to filter out the rare and ambiguous words. Secondly, you will calculate the similarity scores for pairs of words in the filtered dataset using Lin similarity, NPMI and LSA. Lastly, you will quantify how well these methods work by comparing to a human annotated gold-standard.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eDownload the \u003ca class=\"instructure_file_link\" href=\"viewer/files/02-assignment.ipynb?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003ejupyter notebook\u003c/a\u003e and \u003ca class=\"instructure_file_link\" href=\"viewer/files/set1.tab?canvas_download=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003ethe dataset\u003c/a\u003e and follow the instructions to complete the assignment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eThe submission deadline is \u003cstrong\u003eThursday, 4 June 2020, 5pm\u003c/strong\u003e. Please submit the completed notebook via Canvas. \u003cstrong\u003eImportant: Remember to write your name and student ID in the notebook.\u003c/strong\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003ePlease feel free to ask any questions about the assignment on the discussion board (without revealing your answers, of course). You can also email me if there are further questions.\u003c/span\u003e\u003c/p\u003e","submissionTypes":"a file upload","graded":true,"pointsPossible":10.0,"dueAt":"2020-06-04T17:00:00+10:00","lockAt":null,"unlockAt":null},{"exportId":"g1a60cc3f1fee2b7add4ec73c3747c07b","title":"Project - Climate Change Misinformation Detection","type":"Assignment","content":"\u003cp\u003e\u003cspan\u003eIn this project, you'll be working on a document classification problem. The task is to classify whether a document contains climate change misinformation. This project involves implementing a misinformation detection system and writing a report to describe your system. This is an \u003cstrong\u003eindividual\u003c/strong\u003e project.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eDownload the \u003ca title=\"project.pdf\" href=\"viewer/files/project.pdf?canvas_download=1\" name=\"project.pdf\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2936678\" data-api-returntype=\"File\"\u003eproject specification\u003c/a\u003e and follow the instructions to complete the project. Project files can be downloaded \u003ca title=\"project-files.zip\" href=\"viewer/files/project-files.zip?canvas_download=1\u0026amp;canvas_qs_download_frd=1\" name=\"project-files.zip\"\u003ehere\u003c/a\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cdiv class=\"page\" title=\"Page 1\"\u003e\r\n\u003cdiv class=\"layoutArea\"\u003e\r\n\u003cdiv class=\"column\"\u003e\r\n\u003cp\u003e\u003cspan\u003eDue date: 9pm Wed, 13\u003c/span\u003e\u003cspan\u003eth \u003c/span\u003e\u003cspan\u003eMay 2020\u003cbr\u003eCodalab due date: 1pm Wed, 13\u003c/span\u003e\u003cspan\u003eth \u003c/span\u003e\u003cspan\u003eMay 2020 \u003c/span\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cp\u003e\u003cspan\u003ePlease submit your zipped project files via Canvas (see the project specification for details).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003ePlease feel free to ask any questions about the project on the discussion board (without giving out too much of your ideas). You can also email me if there are further questions.\u003c/span\u003e\u003c/p\u003e","submissionTypes":"a file upload","graded":true,"pointsPossible":40.0,"dueAt":"2020-05-13T21:00:00+10:00","lockAt":null,"unlockAt":null}],"discussion_topics":[{"exportId":"gfc7f13c7715463672e941dc11218f0de","title":"Assignment 1-Q4","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003eHere is a little question about Q4 in assignment1. When updating BOW of preprocessed events, do i need to delete the item '#' and its frequnence for each event?\u003c/p\u003e\r\n\u003cp\u003eBest regards\u003c/p\u003e\r\n\u003cp\u003eThanks!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga0538194fdd7be1d7f38cbff30c3e7bb","title":"Assignment1 - Q6","type":"DiscussionTopic","content":"\u003cp\u003eHi staff team,\u003c/p\u003e\r\n\u003cp\u003eI read some discussions on db, and I find two different standards  about parameter tuning in  Q6, but I don't know if I misunderstand any one of them. According to Jey Han, he said we can only use development set, but Zenan said we should train our model on training set and evaluate the model with different params on development set (two links are attached below). So I'd like to find the right method to tune parameters.\u003c/p\u003e\r\n\u003cp\u003e\u003ca title=\"Link\" href=\"discussion_topics/g6cfd2ce15b6696b401294b3f1dccd9ca\" target=\"_blank\"\u003eJey Han\u003c/a\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca title=\"Link\" href=\"discussion_topics/g1027fd3f0efedc4e4137ece07ab28d26\" target=\"_blank\"\u003eZenan\u003c/a\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gdf05e6dc152dbdbe52a2d85e5a759f3d","title":"Assignment 1:Ques-3","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eFor ques 3, if we have #PrayForSydney, I am getting ['#', 'Pray', 'F', 'orS', 'y', 'd', 'n', 'ey'] (sydney is not there in the dictionary), 'ors' after being lemmatized becomes 'or' so 'ors' gets added to the list whereas 'fors' does not get lemmatized to 'for' . Is this correct or I am missing something?\u003c/p\u003e\r\n\u003cp\u003eAlso, for #friendzz, ['#', 'friend', 'z', 'z'], are we supposed to keep duplicate tokens like 'z' here?\u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e\r\n\u003cp\u003ePratibha\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc90b8acf952e516db9cf492710e67c63","title":"Assignment Q3","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eFor Q3, the way I use nltk.pos_tag() is like this:\u003c/p\u003e\r\n\u003cp\u003eFor example, hashtag = \"#LovedUs\", and the algorithm splits the hashtag into \"loved\", \"us\"\u003c/p\u003e\r\n\u003cp\u003eI pass \"loved\" and \"us\" into the pos_tag function. Then the function will return me (\"loved\", VERB), (\"us\", NOUN).\u003c/p\u003e\r\n\u003cp\u003eHowever, if I pass \"us\" and \"loved\" into the function, it will return me (\"us\", NOUN), (\"loved\", NOUN).\u003c/p\u003e\r\n\u003cp\u003eSo do we need to care about this? Or is it something we should try and test it out, then choose a better one?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e(Or should I just pass 1 word into the function, instead of 2 words? i.e. just \"us\")\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g1a523dfd5da44128d5e250a93fff74e4","title":"Byte-Pair Encoding","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI have two questions about this algorithm:\u003c/p\u003e\r\n\u003cp\u003e1. As we get a new \"word\" one by one by merge characters, when should we stop merge?\u003c/p\u003e\r\n\u003cp\u003e2. After we stop merge, which words should be our final token? All words in the vocabulary or several of them?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eCan anyone help me with that? Thank you!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g9714d0fb47d12da15c2288cd7a8c24c6","title":"Other Questions","type":"DiscussionTopic","content":"","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g50ec1076f0f6941bdbe7a118be4886ff","title":"Emission probability of the first tag","type":"DiscussionTopic","content":"\u003cp\u003eFor the first tag, does it mean we only need the transitive probability(e.g. P(NN|\u0026lt;s\u0026gt;)) in the argmax equation?\u003c/p\u003e\r\n\u003cp\u003eWhy do we need to  have a transitive probability of the first tag instead of just initialising the probability of the first tag (e.g. P(NN)*P(VB|NN)... instead of P(NN|\u0026lt;s\u0026gt;)*P(VB|NN)...? \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":"2020-03-16T00:00:00+11:00","graded":false},{"exportId":"gf30998cce4c3df2a6d7eee628fa33edb","title":"Foreign language Tweets","type":"DiscussionTopic","content":"\u003cp\u003eWhile tokenizing hashtags, I have encountered a foreign language hashtag. While appending it's tokenized form in the final dictionary I am getting the below output because of the fact the way this language is written. Should I consider this hashtag or not?\u003c/p\u003e\r\n\u003cpre\u003e('#المهاجم', ['#', 'ا', 'ل', 'م', 'ه', 'ا', 'ج', 'م'\u003c/pre\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g8d21c514f30057b5282b02535c2a9802","title":"Assignment1 - Q3","type":"DiscussionTopic","content":"\u003cp\u003eHi Teaching Team: \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e5. What do you mean by 'a reversed version' of the Max Matching algorithm?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"viewer/files/Uploaded%20Media/Screen%20Shot%202020-03-26%20at%209.01.31%20am.png\" alt=\"Screen Shot 2020-03-26 at 9.01.31 am.png\" width=\"226\" height=\"218\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2833527\" data-api-returntype=\"File\" data-id=\"2833527\"\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-size: 1rem;\"\u003eIt means that the match starts from the last character and move character from right to left at each time. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cspan style=\"font-size: 1rem;\"\u003eCould you please check if my understanding is correct?\u003c/span\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e#speakup\u003c/p\u003e\r\n\u003cp\u003espeakup\u003c/p\u003e\r\n\u003cp\u003epeakup\u003c/p\u003e\r\n\u003cp\u003eeakup\u003c/p\u003e\r\n\u003cp\u003eakup\u003c/p\u003e\r\n\u003cp\u003ekup\u003c/p\u003e\r\n\u003cp\u003eup (in wordlist) --\u0026gt; token = 'up'\u003c/p\u003e\r\n\u003cp\u003e#speak\u003c/p\u003e\r\n\u003cp\u003espeak (in wordlist) --\u0026gt;token = 'speak'\u003c/p\u003e\r\n\u003cp\u003e# (leftover - single charater)\u003c/p\u003e\r\n\u003cp\u003etoken = '#'\u003c/p\u003e\r\n\u003cp\u003e'#speakup' : ['#', 'speak', 'up']\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g4345e27eb396cd3bec4a7e542c658cf1","title":"Question about dependencies","type":"DiscussionTopic","content":"\u003cp\u003eHi, I noticed that some 'nltk' functions require extra dependencies to be downloaded in the first time, for example, in question 2 the given code shown below:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eimport nltk\u003c/strong\u003e\u003cbr\u003e\u003cstrong\u003efrom nltk.corpus import stopwords\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cstrong\u003estopwords = set(stopwords.words('english'))\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eThis code script creates a stopword set, but it requires '\u003cstrong\u003enltk.download('stopword')\u003c/strong\u003e' to get the stopword data from nltk server (I guess?). So I'm wondering do I need to include these downloading codes in the assignment, or, I can assume that the marker's computer already has these dependencies so it's not necessary to do so?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gd93f2469bf01043a6c7849222eabbfa6","title":"Porter Stemmer Clarification","type":"DiscussionTopic","content":"\u003cp\u003eHey all,\u003c/p\u003e\r\n\u003cp\u003eJust looking for some clarification about a certain porter stemmer rule, i don't understand how this one works. Shouldn't \"feed\" result in the pattern:\u003c/p\u003e\r\n\u003cp\u003eC(VC) which means that \"m\" is in fact greater than zero and so you replace EED -\u0026gt; EE? Or have i misinterpreted somewhere? I have attached a picture of the rule that is in the slide set.\u003c/p\u003e\r\n\u003cp\u003eThanks!!\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/files/2683015/download?wrap=1\" alt=\"Capture.png\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/files/2683015\" data-api-returntype=\"File\"\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga6a47bf970dbf7cfc554e168a061ae27","title":"Assignment 1 - Q3: Numbers and underscores","type":"DiscussionTopic","content":"\u003cp\u003eHi Tutor Team, \u003c/p\u003e\r\n\u003cp\u003eJust would like to have some clarification on the process of numbers and underscore in tags, given twitter tags can contain letters, numbers and underscores.\u003c/p\u003e\r\n\u003cp\u003eIf we define the resultant tokens are only composed of letters, then all the numbers and special characters  in tags shall be removed, agree?\u003c/p\u003e\r\n\u003cp\u003eOtherwise, I assume we need to seperate single number or underscore from letters/words?\u003c/p\u003e\r\n\u003cp\u003eThen what about consecutive numbers or a mix of number and underscores? \u003c/p\u003e\r\n\u003cp\u003eUpon that, the underscore is normally used as separator, so I reckon it is reasonable to ignore it in the final output?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eFor example, shall we break the tag \"#test123_2_one2\" into which of the following four, or something else?\u003c/p\u003e\r\n\u003cp\u003eA. [\"#\", \"test\", \"123\", \"_\", \"2\", \"_\", \"one\", \"2\"]\u003c/p\u003e\r\n\u003cp\u003eB. [\"#\", \"test\", \"1\", \"2\", \"3\", \"_\", \"2\", \"_\", \"one\", \"2\"]\u003c/p\u003e\r\n\u003cp\u003eC. [\"#\", \"test\", \"123\", \"2\", \"one\", \"2\"]\u003c/p\u003e\r\n\u003cp\u003eD. [\"#\", \"test\",  \"one\"]\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003ePlease clarify.  Thanks. \u003c/p\u003e\r\n\u003cp\u003eRegards,\u003c/p\u003e\r\n\u003cp\u003eKan\u003c/p\u003e","lockAt":null,"unlockAt":"2020-03-28T00:00:00+11:00","graded":false},{"exportId":"g03a9a817d3b7b6fd5450988c3983bdb3","title":"Assignment 1 - Q3","type":"DiscussionTopic","content":"\u003cp class=\"p1\"\u003eHi, Teaching team\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eIn question3, instruction gives an example “a hashtag, ‘#speakup” should produce [“#”, “speak”, “up”]”.\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eI got the same result when I test the code with given hashtag.\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p2\"\u003eI’m confused about MaxMatch algorithm to tokenize a hashtag.\u003c/p\u003e\r\n\u003cp class=\"p2\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e1).\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eWhen I set a test hashtag like ‘#speakingup’,\u003cspan class=\"Apple-converted-space\"\u003e  \u003c/span\u003eI expected a list of word tokens like [‘#’, ‘speaking’, ‘up’] because a word, ‘speaking’, is variant of ‘speak’.\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eBut, my algorithm returns [‘#’, ’s’, ‘p’, ‘e’, ‘akin’, ‘gup’] because a word ‘gup’ is in the given list of words and the matched length of ‘gup’ is longer than ‘up’.\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eThus the following steps, my algorithm seperates the rests in to ‘akin’ -\u0026gt; ‘e’ -\u0026gt; ‘p’ -\u0026gt; ’s’ -\u0026gt; ‘#’\u003c/p\u003e\r\n\u003cp class=\"p2\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eIs this result correct for ‘#speakingup’ with MaxMatch algorithm?\u003c/p\u003e\r\n\u003cp class=\"p2\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p2\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e2).\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e‘#Keeping’ is ‘keep’ + ‘ing’\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eSo I expect the result of [‘#’, ‘Keeping’]\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eIn the word list, there is ‘keep’, but not ‘Keep’ with the capital character.\u003c/p\u003e\r\n\u003cp class=\"p2\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eCan I lowercase the substring of a word if I need to lemmatize?\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e(But the final result shows original form. ( return [‘#’, ‘Keeping’], not [‘#’, ‘keeping’]) )\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eI'm confused whether I can match the word with original form or modified form.\u003c/p\u003e\r\n\u003cp class=\"p1\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p2\"\u003e \u003c/p\u003e\r\n\u003cp class=\"p1\"\u003eThanks.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gd408e1b8470ed446739c2889888f7eca","title":"assignment 1 Q3","type":"DiscussionTopic","content":"\u003cp\u003eWhen we tokenize hashtags like #MentallyChanged,  we can find 'metal' and 'change' are in words.    What kind of forms of output should we choose?  ['#', 'mental', 'change'] or ['#', 'Mental', 'Change'] or ['#', 'mentally', 'changed'] or ['#', 'Mentally', 'Changed'] \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g7a57afc21fb52d4ff2dda5e263efc4dc","title":"Question 6 - Preservation of the ration of rumour/non-rumour events","type":"DiscussionTopic","content":"\u003cp\u003eShould the ratio of rumour:non-rumour events be 1:1? \u003c/p\u003e\r\n\u003cp\u003eOr if the rumour:non-rumour events is currently about 2:5 does that mean that the sets all need a ratio of 2:5 in them?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gbec3996e5b2b755b6d8d91c78bd981ce","title":"Assignment 1: assertions cannot be satisfied","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\u003cp\u003eI have used the provided code to download the tweets, and note that there are many more tweets there than the assertions in your code indicate. For example:\u003c/p\u003e\u003cp\u003e \u003c/p\u003e\u003cp\u003e\u003cspan\u003efind rumours/ -type f | wc -l\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003e7556\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003efind non-rumours/ -type f | wc -l\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003e17332\u003c/span\u003e\u003c/p\u003e\u003cp\u003e \u003c/p\u003e\u003cp\u003eYour assertions indicate 500 and 1000 tweets respectively. See further the attached screenshot and note the line numbers.\u003c/p\u003e\u003cp\u003eWhat's happening here? My notebook points to \u003ca href=\"https://github.com/jhlau/jhlau.github.io/blob/master/files/rumour-data.tgz\" target=\"_blank\"\u003ehttps://github.com/jhlau/jhlau.github.io/blob/master/files/rumour-data.tgz\u003c/a\u003e.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g153853cf380d70e892a956de855639ab","title":"Backofff","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eI am wondering is backoff smoothing for the unigram LM valid? Because the unigram model does not has a lower order n-gram model. \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gba2be7382d11c7022d162c81c92feb03","title":"The Porter Stemmer","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003eLet's say I have a string \"BY\", I want to know what is its [C](VC)\u003csup\u003em\u003c/sup\u003e[V] form.\u003c/p\u003e\r\n\u003cp\u003eMy answer is CV, because refer to \u003cspan\u003eA \u003c/span\u003e\u003ci\u003econsonant\u003c/i\u003e\u003cspan\u003e in a word is a letter other than A, E, I, O or U, and other than Y preceded by a consonant.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e(refer to this page\u003ca href=\"http://snowball.tartarus.org/algorithms/porter/stemmer.html\"\u003ehttp://snowball.tartarus.org/algorithms/porter/stemmer.html\u003c/a\u003e)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eIf anyone knows the true answer?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g49a656ed1a350d26cdf4eb23a97cae1f","title":"Confused about *o and CVC from the Port Stemmer","type":"DiscussionTopic","content":"\u003cp\u003eI am confused by what C and V really mean.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/GUsU2fk.png\" alt=\"\"\u003e\u003c/p\u003e\r\n\u003cp\u003eI thought that because the cease ends in VCV and VC exists in cease and cease ends in e and so that was why cease was getting replaced with ceas.\u003c/p\u003e\r\n\u003cp\u003eI tried to do one more example by myself, but it seemed to contradict this. \u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/rl8c58K.png\" alt=\"\"\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-family: sans-serif; font-size: 1rem;\"\u003eShouldn't fail be replace by faile because it also ends in CVC? Unless each vowel should be V and each consonant should be C and so fail would be CVVC instead and cease should be CVVCV instead?\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g37391b1cde56deccf16f84e122e46f57","title":"Assignment 1- Question 2","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eIn Question 2, \"\u003cspan\u003eThe function takes \u003c/span\u003e\u003cstrong\u003ea list of events\u003c/strong\u003e\u003cspan\u003e as input, and returns \u003c/span\u003e\u003cstrong\u003ea list of preprocessed events\u003c/strong\u003e\u003cspan\u003e. Each preprocessed event should have a dictionary of words and frequencies.\" What does that mean? \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eFor example, if an event consists of \"I\" \"eat\" \"apple\", and their frequencies are 1,1,1 respectively. What should it return?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e[[\"I\",\"eat\",\"apple\"],[1,1,1]] or [\"I\",1,\"eat\",1,\"apple\",1]\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eWhen I try to run the get_all_hashtags function by using the former kind of representation, there is an error. So could you please clarify what kind of representation should I use?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eThanks,\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eXinnan Shen\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gf8e7e41ea489d6c809790eeb17248a25","title":"Lecture Questions","type":"DiscussionTopic","content":"","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g64597f5a9cb491c50be3f38c899cb023","title":"Worksheet for week 3: Laplacian smoothing for bigrams","type":"DiscussionTopic","content":"\u003cp\u003eHi all, a bit confused about the worksheet for week 3 solutions. They say that the vocabulary size for bigram Laplacian smoothing (2 iv.) is 11, but there are 20 different bigrams in the corpus.  Shouldn't we be smoothing based on the number of bigrams, if we pretend we saw each 1 more time than we actually did? What am I missing?\u003c/p\u003e\r\n\u003cp\u003eI guess my question is why we only need to add the number of words, even when our feature set is n-grams. Is it the case that the conditional probabilities for each word must add to 1/|V|?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc2f72249c82218bf9a1e787537943e3c","title":"A1-Q7: OK to retrain models on training + development set?","type":"DiscussionTopic","content":"\u003cp\u003eIn question 7, are we allowed/expected to re-train our classifiers using the combined train and development set before evaluating them against the test set?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g4b31c6bfd8da1d8c868307e1a3ab07c3","title":"assignment 1 question","type":"DiscussionTopic","content":"\u003cp\u003ehi teaching team, \u003c/p\u003e\r\n\u003cp\u003eI have 2 question about problem 6:\u003c/p\u003e\r\n\u003cp\u003e1.\u003c/p\u003e\r\n\u003cp\u003eis it allowed to add cells below the question cell in notebook?\u003c/p\u003e\r\n\u003cp\u003efor example in question 6, I understood that we need to print out the result of parameter tuning for each parameter that has changed. \u003c/p\u003e\r\n\u003cp\u003eso it's more easy to check if I add cells for printing out different results \u003c/p\u003e\r\n\u003cp\u003eor do we just need to do it on one given problem cell?\u003c/p\u003e\r\n\u003cp\u003e2.\u003c/p\u003e\r\n\u003cp\u003eif I found out that the best accuracy result came out without parameter tuning, should I use it for near - optimal result? \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003ethank you\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga999cad4340bd78c32ebc00dc4dc6f10","title":"Assignment1 Q5","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team.\u003c/p\u003e\r\n\u003cp\u003eI'm still confused about Q5\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e(Q5 task : Using scikit-learn, create training, development and test partitions with a 60%/20%/20% ratio. Remember to preserve the ratio of rumour/non-rumour events for all your partitions. Next, turn the bag-of-words dictionary of each event into a feature vector, using scikit-learn \u003c/span\u003e\u003ccode\u003eDictVectorizer\u003c/code\u003e\u003cspan\u003e.)\u003c/span\u003e .\u003c/p\u003e\r\n\u003cp\u003eI understand Q5 task like below picture(Below text data is sample text, not in the assignment dataset.)\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://canvas.lms.unimelb.edu.au/users/34098/files/2893277/preview?wrap=1\u0026amp;verifier=5IrqgRWFFQJ8yX9ze36eJGzUzjUyLid9ZG8wmBSX\" alt=\"스크린샷 2020-03-31 오후 3.16.00.png\" width=\"640\" height=\"322\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/users/34098/files/2893277\" data-api-returntype=\"File\"\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eFollowing above process, I got the 3 different lists of feature vectors.\u003c/p\u003e\r\n\u003cp\u003eBut, feature vectors' attributes are different each other.\u003c/p\u003e\r\n\u003cp\u003eFor example,\u003c/p\u003e\r\n\u003cp\u003efrom Development partition, I can get the features      \u0026lt;she, is, a, beautiful, girl, singing\u0026gt;,\u003c/p\u003e\r\n\u003cp\u003ebut from Test partition, I can get the features                   \u0026lt;she, he, has a brother,  sister\u0026gt;\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eSo, I think the above 3 lists of feature vectors should have combined features, when I try to extract a list of feature vectors from each partition.\u003c/p\u003e\r\n\u003cp\u003e1) from below different features\u003c/p\u003e\r\n\u003cp\u003eTraining : \u0026lt;he, is, in, his, office, sat, under, a tree, she works, at, home, intelligent, visits, hospital, beautiful\u0026gt;\u003c/p\u003e\r\n\u003cp\u003edevelopment : \u0026lt;she, is, a, beautiful, girl, singing\u0026gt;\u003c/p\u003e\r\n\u003cp\u003etest : \u0026lt;she, he, has, a, brother,  sister\u0026gt;\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e2) to combined features\u003c/p\u003e\r\n\u003cp\u003eTraining  : \u0026lt;he, is, in, his, office, sat, under, a, tree, she works, at, home, intelligent, visits, hospital, beautiful, girl, singing, has, brother, sister\u0026gt;\u003c/p\u003e\r\n\u003cp\u003edevelopment : \u0026lt;he, is, in, his, office, sat, under, a, tree, she works, at, home, intelligent, visits, hospital, beautiful, girl, singing, has, brother, sister\u0026gt;\u003c/p\u003e\r\n\u003cp\u003etest : \u0026lt;he, is, in, his, office, sat, under, a, tree, she works, at, home, intelligent, visits, hospital, beautiful, girl, singing, has, brother, sister\u0026gt;\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eI think 2) approach is right way. Because when I predict the test dataset from trained classifier, they must have same features. If not code return the error message.\u003c/p\u003e\r\n\u003cp\u003eWhich approach is right way to solve Q5 and Q6?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g8f2e5760a0a13a738f280daed58559d7","title":"Project Questions","type":"DiscussionTopic","content":"","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g6cd8c268a28a64e00de2e95a1a451a40","title":"Import other methods for Assignment","type":"DiscussionTopic","content":"\u003cp\u003eCould I import other methods from sklearn when doing the assignment? \u003c/p\u003e\r\n\u003cdiv id=\"gtx-trans\" style=\"position: absolute; left: 641px; top: 50.4px;\"\u003e\u003c/div\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g981181749cce3a11946e520099a2d286","title":"The lecture capture","type":"DiscussionTopic","content":"\u003cp\u003eI think that it's missing again! ^^\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g26ad0d09a4df60f6e89cb1dde229f78d","title":"Assignment 1 Q3","type":"DiscussionTopic","content":"\u003cp\u003eWould #SpeakingUp be tokenized as #, Speaking, Up or #, Speak, Up? i.e. are the tokens kept in their original form or lemmatized form? Thank you.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gaeb0bcaccecfcde95dd46590db05abfb","title":"Assignment1-Q3","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003eHow can we do if we meet misjudgement when we use nltk.tag.pos_tag? For example, it regarded \"stayed\" as NN, so that the past tense cannot be restored. Actually it should be belonged to VBN.\u003c/p\u003e\r\n\u003cp\u003eHas anyone else encountered a similar problem？\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g071929746793687869cb3a1f9d2b14f2","title":"Assignment 1 Q3 Case Sensitivity","type":"DiscussionTopic","content":"\u003cp\u003eHello there,\u003c/p\u003e\r\n\u003cp\u003eI have a question about how cases should be dealt with in Q3 before applying the reversed Max Match Algorithm.\u003c/p\u003e\r\n\u003cp\u003eIf I ignore all cases, tags like #AttackInOttawa will become ['#', 'Attac', 'kIn', Ottawa'] because the word 'kin' is in the WordNet database.\u003c/p\u003e\r\n\u003cp\u003eOn the other hand if I consider cases, tags like #AustraliaStrong will become ['#', 'Australia', 'S', 'tron', 'g'] because 'Strong' with the capitalized 'S' is not in the WordNet database.\u003c/p\u003e\r\n\u003cp\u003eShould I apply certain very specific rules (e.g. only the first character can be capitalize), or should I just leave it as it is?\u003c/p\u003e\r\n\u003cp\u003eThank you.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g3330b2e2d28b74c46b5d68e81548a6ef","title":"What is the difference between Interpolation, Interpolated Kneser-Ney Smoothing and Kneser-Ney Smoothing? Why and When should we use one over the others?","type":"DiscussionTopic","content":"\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/files/2695660/download?wrap=1\" alt=\"C3F25A86-000E-415C-B176-9DA0257B3BDA.png\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/files/2695660\" data-api-returntype=\"File\"\u003e \u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eBackoff is a way of combining n-gram models. KN Smoothing is an improved version of backoff. Yet Interpolation is a better way of combing n-gram models. So can I assume that Interpolation is better than KN Smoothing, and KN Smoothing is better than Backoff (I.e, Interpolation \u0026gt; KN Smoothing \u0026gt; Backoff)?\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-family: sans-serif; font-size: 1rem;\"\u003eThen how about Interpolated KN Smoothing? \u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ge95ba94773c1ea718cf5c89738f95a43","title":"Workshop worksheet.","type":"DiscussionTopic","content":"\u003cp\u003eHi, \u003c/p\u003e\r\n\u003cp\u003eI just attended an online workshop. There was no information about the workshop worksheet. \u003c/p\u003e\r\n\u003cp\u003eSo I am a bit confused. Is the worksheet not for workshops? Are we going to do/talk about the worksheet during workshops in later workshops?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g2e6da0b0bad996d685ed881d2a86480d","title":"Assignment 1-Q3","type":"DiscussionTopic","content":"\u003cp\u003e\u003cspan\u003eHi  Teaching team\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eIn question 3, it requires to provide POS information, but the output of this task is a dictionary where key=\"hashtag\" and value=\"a list of word tokens\". So, where should I include this POS information? Should I include it in lists of word tokens?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eRegards\u003c/p\u003e\r\n\u003cp\u003eLinxuan\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g9afbcd9fd7f004188973907738afbace","title":"Assignment 1:Ques-3","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003eFor question 3, if the word of hashtags are #Prayforsydney, after reverse matching I am getting ['ey', 'n', 'syd', 'for', 'Pray', '#']. Do I need to reverse this? to ['#', 'Pray', 'for', 'syd', 'n', 'ey'] or just keep it as it is?\u003c/p\u003e\r\n\u003cp\u003eSo at the end of tokenize hashtags it will be:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003etokenized_hashtags = {\"#Prayforsydney\": ['ey', 'n', 'syd', 'for', 'Pray', '#'], etc}\u003c/strong\u003e\u003cstrong\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eJust want to double check for reversemaxmatch if it isn't in dictionary then we need to return the last letter and repeat the scans right? for example if the words are かがみ then it will return [み,が,か]\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eRegards,\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gd786c791d270f534023b7029a7fe2029","title":"Query regarding reversed version of the MaxMatch algorithm","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI am little confused regarding the expected approach and correct meaning of \"reversed\" version of MaxMatch algorithm. There could be 2 possible approaches.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eApproach 1:\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://canvas.lms.unimelb.edu.au/users/29512/files/2805615/preview?wrap=1\u0026amp;verifier=SGvsHeznSO1AjGA3eeOPtwBZ7VfSBfcjLlBXJP2K\" alt=\"approach_1 (1).png\" width=\"400\" height=\"369\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/users/29512/files/2805615\" data-api-returntype=\"File\"\u003e\u003c/p\u003e\r\n\u003cp\u003eIn this approach, we start from the last character and move matching 1 character in reverse as shown by the arrows till the first character. We then store the maximum matched word and start again with remaining characters.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eApproach 2:\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://canvas.lms.unimelb.edu.au/users/29512/files/2805627/preview?wrap=1\u0026amp;verifier=mrPg7WVy7oonP6sGNtvj8q66yxRlCrOTpGgd4QUP\" alt=\"approach_2 (3).png\" width=\"400\" height=\"340\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/users/29512/files/2805627\" data-api-returntype=\"File\"\u003e\u003c/p\u003e\r\n\u003cp\u003eIn the approach, we start from the first character and match entire word first and then move back character-by-character for matching. \u003c/p\u003e\r\n\u003cp\u003ePlease let me know.\u003c/p\u003e\r\n\u003cp\u003eThanks and Regards,\u003c/p\u003e\r\n\u003cp\u003eAbhinav\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g9bb41661875f12d915835da3b23f9458","title":"Lecture 2 question - Lidstone smoothing","type":"DiscussionTopic","content":"\u003cp\u003e\u003cimg src=\"https://i.imgur.com/Itn9HrN.png\" alt=\"\"\u003e\u003c/p\u003e\r\n\u003cp\u003ei.imgur.com/Itn9HrN.png\u003c/p\u003e\r\n\u003cp\u003eI am a bit confused about how we get 7 for our vocabulary size - would it be 7 because there are seven words in the table (and those are considered our vocabulary)?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga5b23132d32393102c743cb03e8ede96","title":"POS tagging with HMM","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eWhat's the rationale behind that we do not need to consider the end-of-sentence tag during POS tagging with an HMM?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThe only reason I could think about is that while decoding with the Viterbi ALG. we only look at the previous tag, so for the last word we do not need to consider the end-of-sentence tag.\u003c/p\u003e\r\n\u003cp\u003eHowever, for the n-gram LM, we do consider the end-of-sentence tag, since different word has different likelihood to be the end of a sentence. \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eCould anyone help me with this?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThank you in advance\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g37b1c2400ba7a21bf6dcd143ea5ce4ed","title":"02 BPE - def merge_vocab(pair, v_in) gives a KeyError on  '\\\\w'","type":"DiscussionTopic","content":"\u003cp\u003eRegarding workshop 2, we are asked to define merge_vocab.\u003c/p\u003e\r\n\u003cp\u003eHowever, it seems that if the test case given to merge_vocab in the solution, a key error is obtained. \u003c/p\u003e\r\n\u003cp\u003eI put in \u003cstrong\u003emerge_vocab(('e', '\u0026lt;\\w\u0026gt;'), {'T h e \u0026lt;\\w\u0026gt;':1})\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003ebut it fails with \u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://i.imgur.com/8xGgHPK.png\" alt=\"\"\u003e\u003c/p\u003e\r\n\u003cp\u003eI'm not sure if I have overlooked something ^^;;\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g4a2060c2ee827cf0dacef74a2e746fd4","title":"Assignment 2, topic model slides and workshop documents","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team\u003c/p\u003e\r\n\u003cp\u003eI am thinking about building a topic model for sloving the assignment 2 question. However, I find it is in lecture 21. Can we get the relevant lecture slides and workshop documents earlier? So we can get some ideas about how the topic models work. \u003c/p\u003e\r\n\u003cp\u003eRegards\u003c/p\u003e\r\n\u003cp\u003eLinxuan Zhao\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g61bc4c1e53f8c0cbe6f6808831b9af8f","title":"Lecture Capture missing on the portal for  9:00 AM - March 9, 2020","type":"DiscussionTopic","content":"\u003cp\u003eHi team,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eI could not locate the lecture capture for today's morning lecture.\u003c/p\u003e\r\n\u003cp\u003eWill it be uploaded in a while or was there issues with the video capture?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks,\u003c/p\u003e\r\n\u003cp\u003eRohit\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc2242fd69244639257775eeb9f1376d0","title":"Assignment 1 ","type":"DiscussionTopic","content":"\u003cp\u003eIn the preprocessing part, the second cell extract the file and remove the superfluous files.\u003c/p\u003e\r\n\u003cp\u003eBut after the \"#remove superfluous files (e.g. .DS_store)\" the .DS_store still appears in the list.\u003c/p\u003e\r\n\u003cp\u003eIs that normal?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g7c5236130932d98c5b431f054798468c","title":"Assignment 1 Q6","type":"DiscussionTopic","content":"\u003cp\u003eFor Q6,  are we just changing alpha for MultinomialNB and C in LogisticRegression or do we need to look at all of the other ones as well? Thank you.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g11ff3fe8f6ab8555725be197c9869222","title":"Workshop Questions","type":"DiscussionTopic","content":"","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g137e4458505239ab4e5c4cac60459819","title":"Assignment Q4","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003eIn Q4, when we do have a tokenized hashtags [ '#' , 'Speak' , 'Up' ] and an event document without a word of 'Speak' and 'Up', should we add those word into the document dictionary? So they will have { , 'Speak' = 1, 'Up' = 1}.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003ethank you!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g67aa2ed7a84469299034e049b4366dcd","title":"The meaning of Regex \"(?\u003c!\\S)\" which appears in workshop notebook","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\r\n\u003cp\u003eI don't understand what pattern (?\u0026lt;!\\S) regex matches. This regex appears in  \"merge_vocab\" function in 02-bpe-solution.ipynb. Especially, I cannot figure out what \"!\" in the regex does.\u003c/p\u003e\r\n\u003cp\u003eCould you explain it and hopefully with some examples?\u003c/p\u003e\r\n\u003cp\u003eThank you\u003c/p\u003e\r\n\u003cp\u003eKazuto\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g9a51983d39484e2d9027572863301277","title":"Point 7 in Assignment FAQ list","type":"DiscussionTopic","content":"\u003cp\u003eHi Staffs, \u003c/p\u003e\r\n\u003cp\u003eAccording to, \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"background-color: #bdc3c7;\" data-darkreader-inline-bgcolor=\"\"\u003e\u003cem\u003e\u003cspan style=\";\"\u003e\u003cstrong\u003e7. When I do the reversed max matching, can I lowercase the substring before lemmatization and matching with words in the dictionary?\u003c/strong\u003e\u003c/span\u003e\u003c/em\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"background-color: #bdc3c7;\" data-darkreader-inline-bgcolor=\"\"\u003e\u003cem\u003e\u003cspan style=\";\"\u003eYes, you can and you should do it since any substring with an uppercase letter won't match any entry in the dictionary. But note that you do not need to do lowercasing before/after max matching.\u003c/span\u003e\u003c/em\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eI am confused about the answer. The first sentence seems to imply that you should do lowercase \"before\" MaxMatch while the second sentence says you don't need to. Can you correct me if I am wrong?\u003c/p\u003e\r\n\u003cp\u003eThanks in advance!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g35ecc356509c649d5ff24ae4c3eb645c","title":"Neural network basics [New, added 4th May]","type":"DiscussionTopic","content":"\u003cp\u003e\u003cspan\u003eFor those who are interested to learn more about neural network basics, I've shared some lecture slides and recordings from COMP90049 Introduction to Machine Learning. You can find them on the \u003ca title=\"Neural Network Basics\" href=\"pages/neural-network-basics\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/pages/neural-network-basics\" data-api-returntype=\"Page\"\u003eNeural Network Basics\u003c/a\u003e page (under Modules \u0026gt; Lectures). Hopefully you'll find them useful.\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gaab10ee94b617f1649a1a18f64dde55a","title":"Assignment1 -Q3","type":"DiscussionTopic","content":"\u003cp\u003eHi Staffs,\u003c/p\u003e\r\n\u003cp\u003eI have a question about the lowercasing in Q3.  Firstly, we are allowed to do lowercasing during the MaxMatch algorithm.  So do we need to lowercase the nltk corpus words? Because I find that there are some words starting with uppercase in \"words\". If we only do lowercasing to  substring, some words like \"\u003cspan\u003eleptolepidae\u003c/span\u003e\" can't be found in \"words\", as there are only \"\u003cspan\u003eLeptolepidae\u003c/span\u003e\" in nltk \"words\". But if we do lowercasing to this \"words\",  it will have an influence on the efficiency of the algorithm, because the size of the words is too large.\u003c/p\u003e\r\n\u003cdiv id=\"gtx-trans\" style=\"position: absolute; left: 151px; top: 153px;\"\u003e\u003c/div\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g6cfd2ce15b6696b401294b3f1dccd9ca","title":"Assignment 1 - Q6","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eI am wondering in the Q6, are we only allowed to use the development set? That is we cannot touch on the training and testing set.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g4e8b7264253d838a43ef056cc458222e","title":"Q1","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI want to pass json files to the get_tweet_text_from_json method and need to traverse to the source-tweets and reactions folder for the same. Should I use os.walk() or os.path.join() method?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g416e1e79dde84accebe790e972a413c2","title":"Assignment 1 - Q6 task performance","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eFor Q6, should hyper-parameters be chosen based solely on accuracy, or should other metrics (e.g. macro-averaged F score) be considered as well? The instructions for the question only mention that the accuracy should be printed, but the actual task description says \"\u003cspan\u003eprint the task performance\". So does \"task performance\" just refer to accuracy here? Thanks.\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g0da8974367d7a03ec4ccc89ec90543b9","title":"Question about Back-off  (Lecture 3 page 22)","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI have a question about the Back-off part (Lecture 3 page 22):\u003c/p\u003e\r\n\u003cp\u003eIn the lecture recording, the probability is:\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://canvas.lms.unimelb.edu.au/users/25932/files/2726872/preview?wrap=1\" alt=\"WX20200314-015959@2x.png\" width=\"400\" height=\"146\"\u003e\u003c/p\u003e\r\n\u003cp\u003eHowever, in the slides, it's a bit different about the second case:\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"https://canvas.lms.unimelb.edu.au/users/25932/files/2726873/preview?wrap=1\" alt=\"WX20200314-020021@2x.png\" width=\"400\" height=\"146\"\u003e\u003c/p\u003e\r\n\u003cp\u003eAre they actually the same? Or does the \u003cspan\u003edenominator part of the second case in the slides version equals 1?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gea87e283df00948736ddb94f5294dc0e","title":"Assignment 1 - q3","type":"DiscussionTopic","content":"\u003cdiv\u003eDear teaching team, \u003c/div\u003e\u003cdiv\u003eI have 3 doubts in  q3.\u003c/div\u003e\u003cdiv\u003eIn spite of the length being equal to the hashtags and the preprocessed hashtags, there's an assertion error. I have attached a screenshot. \u003c/div\u003e\u003cdiv\u003eIn addition, the 3rd question doesn't execute without executing the hashtag bit of the code repeatedly. Is this the way Jupyter notebooks work? \u003c/div\u003e\u003cdiv\u003eFinally, I have implemented the POS tagger.. but how do I make sure it is implemented correctly? Is there a way to check?\u003c/div\u003e\u003cdiv\u003e\n\u003cdiv\u003e                nltk.pos_tag(sub_str) #tagging the tokens before lemmatizing\u003c/div\u003e\n\u003cdiv\u003e                lemma_lower = lemmatize(sub_str.lower())    \u003c/div\u003e\n\u003cdiv\u003e                lemma = lemmatize(sub_str)\u003c/div\u003e\n\u003cdiv\u003e                if lemma in words or lemma_lower in words:\u003c/div\u003e\n\u003c/div\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g91a1299e7386b20cf0cae28670959e9b","title":"A1 Q3 : reversed version MaxMatch, identify pos_tag","type":"DiscussionTopic","content":"\u003cp\u003eHi\u003c/p\u003e\r\n\u003cp\u003eIf hashtag is \"#hhhhabc\",  in current turn: I am trying to identify if \"abc\" is a token of the hashtag.\u003c/p\u003e\r\n\u003cp\u003eShould I use \u003cspan\u003enltk.tag.pos_tag([\"hhhh\", \"abc\"]) to  get the pos_tag of \"abc\" before lemmatising?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e\r\n\u003cp\u003eZhixuan\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g6f0ac479c5e28dd506401ef79d47659c","title":"Workshop recordings","type":"DiscussionTopic","content":"\u003cp\u003e\u003cspan\u003eHi,\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eCurrently only workshop recordings from Zenan and Jun are available on LMS.\u003cbr\u003eWill recordings by other tutors be made available as well?\u003c/p\u003e\r\n\u003cp\u003eThanks.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc709e4503b0d84b5a9ce92e0e58c68b0","title":"Assignment Q6","type":"DiscussionTopic","content":"\u003cp\u003eHi, teaching team.\u003c/p\u003e\r\n\u003cp\u003eIn Q6, '\u003cspan\u003eyou do need to print out the accuracy with enough different settings to strongly suggest you have found an optimal or near-optimal choice.'\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e1) In this question, if I find the optimal parameter,\u003c/p\u003e\r\n\u003cp\u003eprint out accuracy means that we can print out accuracy with parameter hard coding on the code in the below way?\u003c/p\u003e\r\n\u003cp\u003e\u0026gt;\u0026gt; parameter = 3,           print( prediction( classifier, parameter ) )\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e2) How much accuracy do you expect for this question 6 as optimal accuracy?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g7eb5e9a81794b533b3c7449f8425bab7","title":"Assignment1-Q4","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI just want to assure my understanding of Q4.\u003c/p\u003e\r\n\u003cp\u003eSo if an event contains a hashtag (let's say) '#speakup' with frequency 1 (apparently with tokenized_hashtag: (['#', 'speak', 'up'])),\u003c/p\u003e\r\n\u003cp\u003e(1) if the current event has no element among ['#', 'speak', 'up'],  we need to add these elements as keys with value 1 to this event\u003c/p\u003e\r\n\u003cp\u003e(2) if the current contains a token 'speak' with value 3, we need to update the value to 4\u003c/p\u003e\r\n\u003cp\u003eIs that right? or please identify my misunderstandings!\u003c/p\u003e\r\n\u003cp\u003eYutong\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g97e3546bd9a7f29c5cc3430cb9834d7c","title":"Assignment 2 Questions","type":"DiscussionTopic","content":"","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g543336a680a1a3c351d7673e2d57c6db","title":"repeating questions in lectures for video recording","type":"DiscussionTopic","content":"Hi Jay,\u003cbr\u003e\u003cbr\u003eWhen watching the lecture recordings we can't normally hear questions from the students. Would you be able to repeat / paraphrase the question before answering so we can hear both the question and your answer on the video recording.\u003cbr\u003e\u003cbr\u003eThanks,\u003cbr\u003eSam","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga83b8c6926761530893e3b37071782c9","title":"Lecture 8 - RNN","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eI am wondering that is the language model based on RNN suffers from the error propagation problems? Since there is a strong dependency between states.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks! \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g5c08e073057e516b3fe03d79554077ee","title":"Assignment1","type":"DiscussionTopic","content":"\u003cp\u003eHi Staffs,\u003c/p\u003e\r\n\u003cp\u003eMay I ask a questions about this assignment? \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eAccording to general info, we need to follow the instructions. So do we need to store the lowercase words  or big letters, which is not mentioned in instructions, when we are doing preprocessing ?\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cdiv id=\"gtx-trans\" style=\"position: absolute; left: 67px; top: 81px;\"\u003e\u003c/div\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gbb1a0bfc62a2c8545e3a193575ff4a27","title":"Is there any requirement for running time of Q6","type":"DiscussionTopic","content":"\u003cp\u003eHi, teaching team\u003c/p\u003e\r\n\u003cp\u003eI tried to use grid search without CV to find a near-optimal hyperparameter combo in Q6. I found that using solver \"newton-gc\" would take a few minutes, which is way slower than using \"lbfgs\". So I was wondering if there is any requirement for the running time?\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eAlso, I run a few tests with different parameter 'C'  ranging from  10^(-3) to 10^3. It turns out best accuracy comes always with the highest  'C' no matter which solver I choose. No surprise this is overfitting. I know we should only choose our parameters based on accuracy. \u003c/span\u003e\u003cspan\u003eDo we really need to think about the overfitting problem? Or we just get the best parameter combo possible and its corresponding accuracy and F score in Q7 regardless of the overfitting problem.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eRegards\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gbf16a5b7b965ec58d30b2aa497b25455","title":"Assignment1-Question3","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching staff,\u003c/p\u003e\r\n\u003cp\u003eIn the instruction, it says that when lemmatizing the substring , a pos tag  of this substring is required. So do I also need to lowercase the substring in \u003cspan\u003enltk.tag.pos_tag function.  Because sometimes the first letter of a hashtag ‘s token is not a capital letter such as “neA”.  Fortunately，the results of neA \u003c/span\u003e\u003cspan\u003eand nea are the same in pos tagging. But if the token is “hIgh”，the result will be different from “high” 's. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e \u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/users/65573/files/2913844/preview?wrap=1\u0026amp;verifier=pA1WzC59MkNkOJdG0MyBUA2TgJg8VnnnL0Giw3Af\" alt=\"1.png\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/users/65573/files/2913844\" data-api-returntype=\"File\"\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g85c1b02f9795d48db90e98c4a3cf7ed7","title":"Assignment question 3,  what is the data type of 'tokenized_hashtags' ?","type":"DiscussionTopic","content":"\u003cp\u003eI'm quite confusing about the data type of variable '\u003cstrong\u003etokenized_hashtags\u003c/strong\u003e' in question 3. The given codes include this line:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eprint(list(tokenized_hashtags.items())[:20])\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eSo '\u003cstrong\u003etokenized_hashtags'\u003c/strong\u003e  seem like a dictionary because only dictionary has item() function, so I guess it should be a dictionary contains tokenized hashtags with \u003cspan\u003ethe part-of-speech tag of the tokenized word.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eHowever, in the testing part, we have this line:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eassert(len(tokenized_hashtags) == len(hashtags))\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003ewhich confuses me a lot, why these two variable have same length? As a hashtag may be expended into multiple tokenized hashtags, if '\u003cstrong\u003etokenized_hashtags' \u003c/strong\u003eis a dictionary of these tokenized hashtags (and it's part-of-speech tag), then the length of '\u003cstrong\u003etokenized_hashtags'\u003c/strong\u003e should be larger than '\u003cstrong\u003ehashtags\u003c/strong\u003e', but here it's equal. So, if it's possible, can you explain what's the data type and the structure of '\u003cstrong\u003etokenized_hashtags' ?\u003c/strong\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc849ad6bbeb05399f1e588ee2a08609f","title":"Assignment1-Q7 label the output","type":"DiscussionTopic","content":"\u003cp\u003eAfter the prediction of test set, should I print the output of prediction or just print the accuracy and classification report?\u003c/p\u003e\r\n\u003cp\u003eFor example, if I use 1 and 0 to represent rumour and non-rumour, should I convert 1,0 to rumour and non-rumour?\u003c/p\u003e\r\n\u003cp\u003eThanks for help.\u003c/p\u003e","lockAt":"2020-04-02T23:59:59+11:00","unlockAt":"2020-04-02T00:00:00+11:00","graded":false},{"exportId":"gdedc0af3627ac84ae4d4c55135636034","title":"Assignment 1: inconsistent results","type":"DiscussionTopic","content":"\u003cp\u003eHi all, I've noticed that because Python salts its hash function, the dictionaries end up in a different order each time Jupyter is restarted. This means that your classification test results will be slightly different each time (unless you take great care to ensure \u003cem\u003eexactly\u003c/em\u003e the same data ends up in the test set regardless of the dictionary ordering).\u003c/p\u003e\r\n\u003cp\u003eIn particular, with my tunings naive Bayes and logistic regression have fairly comparable performance. Logistic regression tends to do better most of the time, but on some unfortunate possible test sets, it does worse. Was wondering what the criteria for correctness are here, and if the teaching team is aware of this inconsistency.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g003e25fb807a4c196f3473eb1cbd4b8b","title":"Assignment 1 Ques 2","type":"DiscussionTopic","content":"\u003cp\u003eHello, \u003c/p\u003e\r\n\u003cp\u003eI have a doubt when it comes to the task of  preprocessing in the second question. Till what level are we supposed to preprocess? I am not able to figure that out.  As to my understanding, preprocessing requires to:\u003c/p\u003e\r\n\u003cp\u003e1. remove the punctuations, stop-words and integers\u003c/p\u003e\r\n\u003cp\u003e2. lowercasing of every word, \u003c/p\u003e\r\n\u003cp\u003e3. remove unwanted symbols like @, $ and also removing URLs as they aren't of much use. \u003c/p\u003e\r\n\u003cp\u003eAm I correct in adopting this level of preprocessing? Please shed some light. Thanks in advance. \u003c/p\u003e\r\n\u003cp\u003eRegards,\u003cbr\u003eGaurang\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g461eaa93ce6f303cce4130d237408040","title":"Query of the second lecture","type":"DiscussionTopic","content":"\u003cp\u003eDear staff team,\u003c/p\u003e\r\n\u003cp\u003eThere are two questions about the second lecture:\u003c/p\u003e\r\n\u003cp\u003e1. As the picture shows, can we say the \"C\" in different positions can represent different characters? If so, what is the difference between C and V?\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/files/2663784/download?wrap=1\" alt=\"Figure1.png\"\u003e\u003c/p\u003e\r\n\u003cp\u003e2.  In practice, do we use the Poter Stemmer with some rules to remove derivational suffixes? What can we do if we meet some negative examples by using this method? Like the example in slides 32, if we set a rule to change \"eed\" to \"ee\", we will meet the negative example like \"feed\".\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks for your help.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g44f9160dc23dafbe0d76a48099e1ce86","title":"Assignment 1 Runtime","type":"DiscussionTopic","content":"\u003cp\u003eHi staffs, \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eCould you give us an approximate \"reasonable amount of time\" that our code should run in? \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eMy MaxMatch function ran in ~8 min. Is it acceptable?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eThank you!\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g4d20e86210837377aa179afc87dd4f8b","title":"Assignment 1 Q4 - matching token in BoW and tokenized hashtags","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003eIn Q4, we are asked to update the BoW with tokenized hashtags resulted in Q3. Since there is no requirement to lemmatize the token in Q2, but there is one in Q3, I'm thinking about possibility where a word of \"Speaking\" in BoW would not be matched to a lemmatized word, \"speak\", in tokenized hashtags. Would that be okay?\u003c/p\u003e\r\n\u003cp\u003eThanks! \u003c/p\u003e\r\n\u003cp\u003e  \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g6ce9c6036e755df14aeb0bf868b768a4","title":"Project question","type":"DiscussionTopic","content":"\u003cp\u003eWhat libraries are installed in Codalab?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g034b67d917b6202d13f845b7f78d7a6a","title":"Assignment1 - Q5","type":"DiscussionTopic","content":"\u003cp\u003e\u003cspan\u003eHi, teaching team\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e1. Should we combine rumour dataset (500 events) and nonrumour dataset (1000 events) as one dataset (1500 events)?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e2. If we combine two datasets as one. Should we create class set (rumour/nonrumour) for this dataset.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e3. Should we only turn the train dataset (900 events) into a feature vector or all the events (1500 events) into a feature vector?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g1027fd3f0efedc4e4137ece07ab28d26","title":" Assignment 1 - FAQ","type":"DiscussionTopic","content":"\u003cp\u003eHere are some questions regarding assignment 1 that are asked frequently.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e1. Should we do any pre-processing steps that are not mentioned in the instructions (e.g. lowercasing)?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eNo, if it is not mentioned in the instruction, please do not do it.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e2. I found some duplicated source tweets and reactions in the dataset, should I remove them?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eNo, just leave it as it is.  \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e3. Can I write functions that are not originally in the notebook to improve the quality of the code?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eYes, please feel free to do so. Nested functions are also allowed.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e4. Can I use packages that are not mentioned in the general info?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eNo, you should not use those packages that are not mentioned (e.g. Pandas).\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e5. What do you mean by 'a reversed version' of the Max Matching algorithm?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"viewer/files/Uploaded%20Media/Screen%20Shot%202020-03-26%20at%209.01.31%20am.png\" alt=\"Screen Shot 2020-03-26 at 9.01.31 am.png\" data-api-endpoint=\"https://canvas.lms.unimelb.edu.au/api/v1/courses/17601/files/2833527\" data-api-returntype=\"File\"\u003e\u003c/p\u003e\r\n\u003cp\u003eIt means the match starts from the last character and move one character from right to left at each time.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e6. Should I include the hashtag itself in the list of tokenized hashtag?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eYes, you should.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e7. When I do the reversed max matching, can I lowercase the substring before lemmatization and matching with words in the dictionary?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eYes, you can and you should do it\u003cstrong\u003e during the MaxMatch\u003c/strong\u003e \u003cstrong\u003ealgorithm (i.e. when lemmatizing the substring and matching it to the dictionary)\u003c/strong\u003e since any substring with an uppercase letter won't match any entry in the dictionary.  But note that you do not need to do lowercasing \u003cstrong\u003ebefore (e.g. in question 2) or after (i.e. in the list of tokenized hashtags) \u003c/strong\u003ethe MaxMatch algorithm.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e8. What are training, development, and test set for?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eYou should always train your model with the training set. For hyper-parameter tuning, you should evaluate your model (trained on the training set) on the development set. The test set is where you should present the final result produced by the best performing model you have.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e9. In what order should we present the list of tokenized hashtags?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eYou should keep the natural order (i.e. the token list of '#SpeakUp' should be ['#', 'Speak', 'Up']).\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e10. What is the expected time complexity of the reversed MaxMatch algorithm?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eIdeally, your algorithm should run in \u003cimg class=\"equation_image\" title=\"O\\left(L^2\\right)\" src=\"https://canvas.lms.unimelb.edu.au/equation_images/O%255Cleft(L%255E2%255Cright)\" alt=\"LaTeX: O\\left(L^2\\right)\" data-equation-content=\"O\\left(L^2\\right)\"\u003e in which \u003cimg class=\"equation_image\" title=\"L\" src=\"https://canvas.lms.unimelb.edu.au/equation_images/L\" alt=\"LaTeX: L\" data-equation-content=\"L\"\u003e is the length of a word. So it should not take up to a few minutes to process all the hashtags. Marks will be deducted accordingly if your code takes too long to finish.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e11. What evaluation metric does the task performance in Question 6 refers to?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eIt refers to \u003cstrong\u003eaccuracy.\u003c/strong\u003e You are encouraged to present any evaluation metric that you think is meaningful in Question 7, but for Question 6, please use accuracy for hyper-parameter tuning.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e12. What package/method can I use?\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003ePlease refer to the general info on what package you can use. Feel free to use the methods provided by these \"prescribed\" packages as long as they do what the instructions ask you to do.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eStay tuned, we will keep updating this list. \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gb87dfac7e50b8fdfe7be6d4c0e96a0c2","title":"The Porter Stemmer Algorithm","type":"DiscussionTopic","content":"\u003cp\u003eHi all,\u003c/p\u003e\r\n\u003cp\u003eIn terms of the step 2,3 and 4 in the Porter Stemmer Algorithm, What's the difference between these steps? Can we just merge the rules refered in three steps?  All these three steps look like collections for different rules to delete derivational inflections.\u003c/p\u003e\r\n\u003cp\u003eI also found some rules in step 4 is subrule for step2 or step3.\u003c/p\u003e\r\n\u003cp\u003eeg. (m\u0026gt;0) ATIONAL -\u0026gt; ATE in step 2\u003c/p\u003e\r\n\u003cp\u003e        (m\u0026gt;1) ATE-\u0026gt; null in step 4\u003c/p\u003e\r\n\u003cp\u003eI guess the reason for dividing these rules into three steps is to completely delte the suffixs. \u003c/p\u003e\r\n\u003cp\u003eLooking forward to you reply. Thanks in advance.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga6e74b8d2524097323e7ef2faf78b221","title":"Q1 and Q2","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\r\n\u003cp\u003eIn q1 and q2, the length of my events are as follows:\u003c/p\u003e\r\n\u003cp\u003eNumber of rumour events = 7556\u003c/p\u003e\r\n\u003cp\u003eNumber of non-rumour events = 17332\u003cbr\u003e\u003cbr\u003eThis doesn't match the 500 and 1000 length.. Is there a specific reason for the same?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g3610a4d6c70ee6be5e80974ecf5064bd","title":"use of matplotlib.pyplot","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\r\n\u003cp\u003eCan I use \" matplotlib.pyplot \" to visualize the results in Q6 and Q7?\u003c/p\u003e\r\n\u003cp\u003eRegards,\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g2fef6a04917505e21f349dfedfac2082","title":"Assignment 1 - Q2 - Number of hashtags","type":"DiscussionTopic","content":"\u003cp\u003eWhat should be the output for the number of hashtags in question 2?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g5775f9b79d140924542ce5ec6f5b75c4","title":"MaxMatch and lemmas","type":"DiscussionTopic","content":"\u003cp\u003eI'm confused about maxmatch. Normally you're interested in finding the longest match but when we're taking the outputs of the match are we taking the length of the lemmatised version or the length of the pre-lemmatised version?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g28919d7feb452d02c6c05f5e701e15f0","title":"Order between Lemmatisation and Stemming","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eWhen we do word normalization, is there an order between Lemmatisation and Stemming?\u003c/p\u003e\r\n\u003cp\u003eOr we just choose one of them in different situations.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g600adb186fd38d065b81070916d3f9dd","title":"About using CrossValidation for Assignment 1 Q6","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI read the posts about Q6 on ds and found out we are not allowed to use cross-validation for tunning. The question shows we are not allowed to use cross-validation on training and testing sets. However, may I use cross-validation on development set only for tunning then? So that I can use gridsearchcv or randomizedsearchcv on development set for tuning the hyper-parameters.\u003c/p\u003e\r\n\u003cp\u003eThank you so much for reading my question.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g2e0a2caa31bedcd665a34f61da65e9a2","title":"Assignment 1 Questions","type":"DiscussionTopic","content":"","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g023d024a2fcc33c73e71e21ed360c39e","title":"Assmt 1: Q5","type":"DiscussionTopic","content":"\u003cp\u003eThe question asks to split the data before vectorizing. Does the order matter? Can we vectorize the data before splitting it?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g7733e3e638c4b4944f411e22d3055bff","title":"Confusion about assignment1 Q3","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\r\n\u003cp\u003eI just really confused about the extra challenge part in Q3.\u003c/p\u003e\r\n\u003cp\u003eIt said for each hashtag we need to \u003cspan\u003econvert them into lemmas before matching.  And when lemmatizing a word, we need to get the part-of-speech tag of the word. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eHowever,  I think if we want to get the part-of-speech tag we need to convert a hashtag into a word list first. I have no idea how to convert a hashtag( like :  #SeeWhatTheyDidThere) into word list ( I think that doesn't make any sense if I use  word_tokenize() from NLTK for a hashtag).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eOr is there just something wrong with my understanding of this question?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eI'll really appreciate your help.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eKind regards,\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eMulin\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g696a13656bc614606634db1da4dda0ce","title":"Assignment 1 reactions and source-tweet","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI found for every event, if \"reactions\" is not empty, it contains the json in \"source-tweet\". Shall we restore this json twice?\u003c/p\u003e\r\n\u003cp\u003eYicheng\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gfc7a0f68adcfe686d800addcc26f6eab","title":"Assignment1 - Q3","type":"DiscussionTopic","content":"\u003cp\u003e1. According to the Reverse Max Match, the priority of ('#trytokeepup' , ['#' , 'tryt' , 'okee' , 'pup']) is higher than ('#trytokeepup' , ['#' , 'try' , 'to' , 'keep' , 'up']) beacuse all of 'tryt', 'okee' and 'pup' exist in nltk.corpus.words.words(). Is this \u003cspan\u003esituation\u003c/span\u003e acceptable?\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/users/134791/files/2844118/preview?wrap=1\u0026amp;verifier=Y77VKEf3o0tXHO0tOmtgdZvwRg22lMYn9vVdFvUg\" alt=\"N75(WA`EM1WK~}R8FI}$FA5.png\" width=\"347\" height=\"26\"\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e2. As the description of Q3, we need to \u003cspan\u003eprint out the last 20 hashtags in the list, but the code in script is for the top 20 hashtags. Need we change this code?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eprint(list(tokenized_hashtags.items())[:20])\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc368c10a3f574245df0cbb51144f98ca","title":"Assignment 1 - Q4","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\r\n\u003cp\u003eThe output of my q2 is a list of dictionaries and is as follows:\u003c/p\u003e\r\n\u003cp\u003epreprocessed_nonrumour_events= [Counter({'@ryanjreilly': 6, \u003cstrong\u003e'#TortureReport': 4\u003c/strong\u003e, 'morning': 4, ':': 3, '.': 3, 'http://t.co/82Ylq2SqzK': 2, '@isshegay': 2, '“': 2, '”': 2, '*': 2,  \u003cstrong\u003e'#PmLive': 1,\u003c/strong\u003e  \u003cstrong\u003e'#religion': 1\u003c/strong\u003e, 'Community': 1, 'cleans': 1, 'streets': 1, ),\u003c/p\u003e\r\n\u003cp\u003eCounter({'shooting': 3, \u003cstrong\u003e'#FergusonPoliceCondemnThemselves': 3\u003c/strong\u003e, 'shot': 3, 'multiple': 3, 'times': 3})]\u003c/p\u003e\r\n\u003cp\u003eThe output of my q3 is a list of tuples and is a follows:\u003c/p\u003e\r\n\u003cp\u003etokenised_hashtags = [\u003cstrong\u003e('#TortureReport', ['#', 'Torture', 'Report'])\u003c/strong\u003e, ('#bestfriendsanyonecouldaskfor', ['#', 'best', 'friends', 'anyone', 'could', 'ask', 'for']), ('#cancer', ['#', 'cancer']), ('#mightierthanthesword', ['#', 'mig', 'h', 'tier', 'than', 'the', 'sword']), \u003cstrong\u003e('#PmLive', ['#', 'P', 'm', 'Live'])\u003c/strong\u003e, \u003cstrong\u003e('#religion', ['#', 'religion'])\u003c/strong\u003e, \u003cstrong\u003e('#FergusonPoliceCondemnThemselves', ['#', 'Ferguson', 'Police', 'Condemn', 'Themselves'])\u003c/strong\u003e]\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eMy doubt is regarding the output of q4, what does updating mean?\u003c/p\u003e\r\n\u003cp\u003eShould it replace '#TortureReport':4 in q2 with ['#', 'Torture', 'Report'] in q3?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eSo the updated list of preprocessed events would be the following:\u003c/p\u003e\r\n\u003cp\u003eupdated_nonrumour_events= [Counter({'@ryanjreilly': 6, \u003cstrong\u003e'#TortureReport': 4,\u003c/strong\u003e\u003cstrong\u003e'#':4, 'Torture':4, 'Report':4,\u003c/strong\u003e 'morning': 4, ':': 3, '.': 3, 'http://t.co/82Ylq2SqzK': 2, '@isshegay': 2, '“': 2, '”': 2, '*': 2,  \u003cstrong\u003e'#PmLive': 1,\u003c/strong\u003e\u003cstrong\u003e'#': 1, 'P',: 1 'm': 1, 'Live': 1\u003c/strong\u003e, \u003cstrong\u003e'#religion': 1,\u003c/strong\u003e\u003cstrong\u003e'#': 1, 'religion': 1\u003c/strong\u003e, 'Community': 1, 'cleans': 1, 'streets': 1, ),\u003c/p\u003e\r\n\u003cp\u003eCounter({'shooting': 3, \u003cstrong\u003e'#FergusonPoliceCondemnThemselves': 3, \u003c/strong\u003e\u003cstrong\u003e'#': 3, 'Ferguson': 3, 'Police': 3, 'Condemn': 3, 'Themselves':3\u003c/strong\u003e, 'shot': 3, 'multiple': 3, 'times': 3})]\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"color: #2fcc71;\"\u003eor should it be the following:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eupdated_nonrumour_events= [Counter({'@ryanjreilly': 6, \u003cstrong\u003e['#', 'Torture', 'Report']: 4,\u003c/strong\u003e 'morning': 4, ':': 3, '.': 3, 'http://t.co/82Ylq2SqzK': 2, '@isshegay': 2, '“': 2, '”': 2, '*': 2, '\u003cstrong\u003e['#', 'P', 'm', 'Live']: 1\u003c/strong\u003e, \u003cstrong\u003e['#', 'religion']: 1\u003c/strong\u003e, 'Community': 1, 'cleans': 1, 'streets': 1, ),\u003c/p\u003e\r\n\u003cp\u003eCounter({'shooting': 3, \u003cstrong\u003e['#', 'Ferguson', 'Police', 'Condemn', 'Themselves']): 3\u003c/strong\u003e, 'shot': 3, 'multiple': 3, 'times': 3})]\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"color: #2fcc71;\"\u003eor should it be the following:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eupdated_nonrumour_events= [Counter({'@ryanjreilly': 6, \u003cstrong\u003e'#':4, 'Torture':4, 'Report':4,\u003c/strong\u003e 'morning': 4, ':': 3, '.': 3, 'http://t.co/82Ylq2SqzK': 2, '@isshegay': 2, '“': 2, '”': 2, '*': 2, \u003cstrong\u003e'#': 1, 'P',: 1 'm': 1, 'Live': 1\u003c/strong\u003e, \u003cstrong\u003e'#': 1, 'religion': 1\u003c/strong\u003e, 'Community': 1, 'cleans': 1, 'streets': 1, ),\u003c/p\u003e\r\n\u003cp\u003eCounter({'shooting': 3, \u003cstrong\u003e'#': 3, 'Ferguson': 3, 'Police': 3, 'Condemn': 3, 'Themselves':3\u003c/strong\u003e, 'shot': 3, 'multiple': 3, 'times': 3})]\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gbdb27eb2ebd97d28975bb11b3b699490","title":"Query of the exam","type":"DiscussionTopic","content":"\u003cp\u003eDear staff team,\u003c/p\u003e\r\n\u003cp\u003eSince the lectures and workshops have been transitioned to online delivery, is it possible to change to the online exam?\u003c/p\u003e\r\n\u003cp\u003eThanks. \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gbf09eeef31771eded985d1cc61b025bf","title":"Assignment1-Q3 ","type":"DiscussionTopic","content":"\u003cp\u003eFor example, hashtag '#nudity_bitterly_cold' after maxmatch, it only returns 'nudi' becuase of '_'. Should I handle this issue? \u003c/p\u003e\r\n\u003cp\u003eIf I delete '_'  in '#nudity_bitterly_cold',  I can get 'nudity', 'bitterly' and 'cold' with maxmatch\u003c/p\u003e","lockAt":"2020-04-02T23:59:59+11:00","unlockAt":"2020-04-02T00:00:00+11:00","graded":false},{"exportId":"ga899d155fba3746e2d95207603da73ea","title":"Question 6 - How much accuracy is  good enough for the final predictions?","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,  I have 3 questions:\u003c/p\u003e\r\n\u003cp\u003e1. How much accuracy is acceptable for the final predictions? I used Grid Search and Random Search to find the best hyperparams  for my models. However, when I try  them on the test set, the results were as not good as I expected (it's not as good as when I make predictions with the validation sets). \u003c/p\u003e\r\n\u003cp\u003e2. Can I remove some features from the training set to get a better result (the instruction does not say whether I'm allowed)?\u003c/p\u003e\r\n\u003cp\u003e3. The hyperparams I used are absolutely the best for the validation set. But it's not certainly the best for the the test set, right. Except the best hyperparams, I also manually used some other hyperparam combinations then realised there existed some better than the best ones I found out. So in practice, it's unsure the hyperparams we found out from a dev set are the best, right?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThank you in advance,\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gff24f08c7fa5ee985315d9cf265d54fd","title":"Assignment 1 - Q3 mapping to wordnet pos format","type":"DiscussionTopic","content":"\u003cp\u003eIn question 3, when I used \u003cspan\u003enltk.tag.pos_tag, it does not give the form that can be used for WordNetLemmatizer(). \u003c/span\u003e\u003cspan\u003eTherefore,  we need to change the the pos tagging into wordnet form. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eThe question is how many different kinds of original pos tagging do we need to take care about? For example do we need to match PRP to wordnet form (but how)? Usually the answers on the internet only cares about adj, adv, verb and noun and treat others as noun. Is that acceptable? \u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gd6bc4902866a41877996c24924a61cd3","title":"Question 6 - Cross Validation on the Development Set?","type":"DiscussionTopic","content":"\u003cp\u003eHi, I have been looking at all the methods of hyperparameter tuning (Grid Search, Random Search) but every sklearn implementation includes cross validation. Is it okay to use GridSearchCV/RandomSearchCV on the development set to find the hyperparameters which are then used on the train/test sets?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc589d7d4e26dbeb4d578da2fcddf6418","title":"Assignment 1 - Q1","type":"DiscussionTopic","content":"In Q1, What the structure of event _list?\u003cdiv\u003e\n\u003cbr\u003e\u003cdiv\u003eFor each event, I use dictionary to distinguish source text and reaction texts ( eg. {“source-tweet”: text, “reactions”: [text1,text2,....]} ).\u003c/div\u003e\n\u003cdiv\u003e\u003cbr\u003e\u003c/div\u003e\n\u003cdiv\u003eOr we just use a sample list to keep all text in source-tweet file and reactions file ( eg. [text,text1,text2,....] ).\u003c/div\u003e\n\u003c/div\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g4e2f9f577be7f57570f1f45fe83ad3d9","title":"Can I introduce Trie into Question 3","type":"DiscussionTopic","content":"\u003cp\u003eHi, teaching team\u003c/p\u003e\r\n\u003cp\u003eI would like to try to write a Class of Node and a Class of Trie for Q3 so that I can speed up word matching. My first thought is to write a couple of lines before tokenize_hashtags(hashtags). Am I allowed to do this?\u003c/p\u003e\r\n\u003cp\u003eRegards\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g3c8890aa0caa1de6bc3868bf493e55d7","title":"Assignment 1 Q2","type":"DiscussionTopic","content":"\u003cp\u003eHello all,\u003c/p\u003e\r\n\u003cp\u003eIn assignment 1 - Q2 I have a doubt.\u003c/p\u003e\r\n\u003cp\u003eDo we need to merge all the tweets in an event to get the frequencies or we still have multiple tweets in single event?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eRegards.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g2bd836787a978b9e159293e773399e4c","title":"Assignment 1 - Q7","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eAre we allowed to use the scikit-learn library for the Q7 or we are asked to do it from scratch?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g3a22b4369ab113efd3dffa18ad8d6cc9","title":"Assignment Q3 - Preprocessing Hashtags","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003eAre we allowed to do hashtag preprocessing in Q? In an example, using regex to remove a number or any special character in the hashtag text? \u003c/p\u003e\r\n\u003cp\u003eThanks!\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g2765f4f945b3d38aedda03f5a973aec6","title":"Question for Assignment1 Q6","type":"DiscussionTopic","content":"\u003cp\u003eHi, teaching team.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eFor the \"main regularisation (hyper)parameters\" in Q6,\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eIn this task, I think the \"alpha\" is the most important parameter in MultinomialNB, \u003c/span\u003e\u003cspan style=\"font-family: sans-serif; font-size: 1rem;\"\u003eand the \"C\"  is also the most important one \u003c/span\u003e\u003cspan style=\"font-family: sans-serif; font-size: 1rem;\"\u003ein LogisticRegression.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e(default value of other parameters are good enough)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eIs that OK to try different values of the most important parameter?  Or should we try to do grid search on multiple parameters?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cpre\u003eMultinomialNB(\u003cstrong\u003ealpha\u003c/strong\u003e=***, class_prior=None, fit_prior=True) \r\n\r\nAccuracy: \r\nMacro-average F-score: \r\n********************************************************************************\r\nLogisticRegression(\u003cstrong\u003eC\u003c/strong\u003e=***, class_weight=None, dual=False, fit_intercept=True,\r\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\r\n                   multi_class='warn', n_jobs=None, penalty='l2',\r\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\r\n                   warm_start=False) \r\n\r\nAccuracy: \r\nMacro-average F-score: \r\n********************************************************************************\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cspan style=\"font-size: 12pt;\"\u003eThanks,\u003c/span\u003e\u003cbr\u003e\u003cspan style=\"font-size: 12pt;\"\u003eFan\u003c/span\u003e\u003c/pre\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ge473aa5c4dc6cf7020037dee858bd2b1","title":"Linguistic basics","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003eI wonder if anyone have any recommendation about basic linguistics for nlp? \u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003cp\u003ekind regards \u003c/p\u003e\r\n\u003cp\u003eRudy\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc141040c5944250ad506d903214380e0","title":"Assignment 1 - Q1","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eThe specification isn't very clear, we need to return a list of lists of the tweet text correct? Also, for each event, there is a source-tweet and reactions. In most events, the first tweet of the reactions is the source-tweet again, so do we repeat the source-tweet text in the event?\u003c/p\u003e\r\n\u003cp\u003ee.g. return value is [[\"source-tweet 1 text\", \"source-tweet 1 text\", \"reaction 1 text\", \"reaction 2 text\", ...], [\"source-tweet 2 text\", \"source-tweet 2 text\", \"reaction 1 text\", ...], [...], ...]\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g2bd770733d67c2b0ebb1ec164db7f1f5","title":"Lecture 7 - Slide 19","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eIn the lecture, the lecturer said that word embeddings implicitly exists between the input layer and the 1st hidden layer. However, I did not get the point. Could someone give me a concrete example to make the word embedding explicit?? \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks !\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g50bae5b375eda7a33bb18792bc4fe0c0","title":"Assignment Q5","type":"DiscussionTopic","content":"\u003cp\u003eHi, teaching team.\u003c/p\u003e\r\n\u003cp\u003eI'm confused about Q5 of assignment 1.\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e\u0026lt;Q5 Instruction\u0026gt;\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e1) Using scikit-learn, create training, development and test partitions with a 60%/20%/20% ratio.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e2) Remember to preserve the ratio of rumour/non-rumour events for all your partitions.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u0026lt;Questions\u0026gt;\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e1) When I create training, development and test partitions with given ratio, should I combine two bag-of-words variables into one bag-of-words variable? \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e(In Q2, I created 2 bag-of-words variables(preprocessed_rumour_events, preprocessed_nonrumour_events) and updated in Q4)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eAssume, 'preprocessed_rumour_events' variable has 100 bag-of-words dictionaries,  'preprocessed_nonrumour_events' also has same 100 bow dictionaries.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eWhat should I return?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e\u0026gt; one training dataset(combined, rumour+non_rumour) and its  number of training dataset is 120(200 * 0.6)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e\u0026gt; two training dataset(separate, rumour, non-rumour) and each number of training dataset is 60(100*0.6)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e2) what is the meaning of 'preserve the ratio of rumour/non-rumour events for all your partitions'?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eI can't understand clearly above instruction.\u003c/span\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga8871201d549fc801fca536b8b74e151","title":"Questions about Ass1","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003eI have some questions about assignment 1. Could you please kindly help me with them?\u003c/p\u003e\r\n\u003cp\u003e1. For Q2, are we allowed to add some other words into the stopwords corpus such as 'I'm', and some punctuations, to improve the downstream steps?\u003c/p\u003e\r\n\u003cp\u003e2. For Q5, I imported the library Random to split dataset into training, dev and test. For example, there are 500 rumour events so I need 300 of them for training. Thus I used Random to generate 300 integers from [1,500] to represents the indexes. However, in this way, everytime I ran the program again, the training, dev and test wouldn't be the same as the last time due to the functionality of Random even though I can guarantee the 60%/20%/20% ratio. Is it okay to do so? \u003c/p\u003e\r\n\u003cp\u003eThank you very much!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g21c7dfafa1df14465450260d73ad7a34","title":"Derivational prefixes","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eStemming is used to solve derivational suffixes, how to deal with derivational prefixes?\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gd6d5a73fcab78048bfce3623da012e2b","title":"About vocabulary in the example of Lidstone Smoothing (Lecture 3)","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eI know this is a closed question answered by \u003cspan\u003eZenan previously. But I still want to know if my understanding is correct.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/users/25932/files/2728124/preview?wrap=1\" alt=\"WX20200314-170901@2x.png\"\u003e\u003c/p\u003e\r\n\u003cp\u003eAs \u003cspan\u003eZenan said before, the |V|=7 because there are 7 bi-grams(5 observed + 2 unknown) in total here. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eDoes it mean that V={impropriety,   offense,   damage,   deficiencies,   outbreak,   infirmity,  cephalopods}  ?\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003eHowever, in the previous add-one case in the sildes, it said that the end mark \u0026lt;/s\u0026gt; is also in V:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/users/25932/files/2728140/preview?wrap=1\" alt=\"WX20200314-171549@2x.png\"\u003e\u003c/p\u003e\r\n\u003cp\u003eSo I think  in the Lidstone Smoothing case, the vocabulary should be the context + observed tokens + end mark\u0026lt;/s\u0026gt; :\u003c/p\u003e\r\n\u003cp\u003eV={alleged, \u003cspan\u003eimpropriety,   offense,   damage,   deficiencies,   outbreak,   \u0026lt;/s\u0026gt;\u003c/span\u003e}\u003c/p\u003e\r\n\u003cp\u003eSo that |V| = 1+5+1=7\u003c/p\u003e\r\n\u003cp\u003eAnd if we have another unseen bi-gram which counts 0 here, the |V| should still be 7.\u003c/p\u003e\r\n\u003cp\u003eIs my understanding correct?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g3fb5adab15b0ab5f37c3e0262727ca14","title":"Question 3 ","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team, \u003c/p\u003e\r\n\u003cp\u003eI've read all of related posts, however I'm still confused with something.  Please give me some answer regarding 'when to do lower casing' issue\u003c/p\u003e\r\n\u003cp\u003eclearly it seems like we need to do lower case at some point of Q3 , but I'm not sure when \u003c/p\u003e\r\n\u003cp\u003eis it need to be done before pos  or before lemmatising, or just before reversed mix match (keep uppercase during pos and lemma) ?\u003c/p\u003e\r\n\u003cp\u003eThank you\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g8d0f5c0cc54b5251cbd8141ad557c871","title":"Assignment 1 - Function","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eAre we allowed to define extra help function? This could improve the code quality, particularly the readability of the code.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gcd5c099f7b9443522d37630b32c5be8e","title":"Correction on Lecture 3,Page 22","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThe lecturer gave a correction on Lecture 3 this morning. He briefly explained it, but I still do not understand what is done in this new equation. \u003cbr\u003eCan anyone give me more explanation on this?\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/users/19865/files/2736800/preview?wrap=1\u0026amp;verifier=NbkRdCXiE2DTeAnNcYrAIQIIF9FpzcRJeekbvFRf\" alt=\"44587240-8B13-4401-A191-FC4A71A5FC18.jpeg\"\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"ga67c913e727c9736dcc8e1a11e8907b5","title":"Embeddings","type":"DiscussionTopic","content":"\u003cp\u003eHi Teaching Staff,\u003c/p\u003e\r\n\u003cp\u003eI have a couple of questions in regards to word embeddings:\u003c/p\u003e\r\n\u003cp\u003e1. Where does the actual values of embeddings come from?\u003c/p\u003e\r\n\u003cp\u003e2. On slide 21, is it correct to assume that the vector x dimension is 8x1?\u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gdc5641e6612147b3b246c2ca635a247d","title":"Q6 hyperparameter tuning standard","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003eI am wondering for Q6,  when I tuning the hyper parameter (alpha, c, etc), should I only take accuracy into consideration and print out each accuracy result, or I should also consider other evaluation metrics such as F1 score. When several alpha values achieve the same accuracy, should I choose a random one between those or use additional metrics to continue choosing an optimal one.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g6df4d2620dc616a027f34775c1cc90f8","title":"Assignment 1 - Q3","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan\u003e\" Create a new list of tokenized hashtags (this should be a list of lists of strings) and use slicing to print out the last 20 hashtags in the list.\"\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eIn the instructions of Q3, it says we need to construct a new list and print the last 20 hashtags, but in the Task it says we need to return a dictionary. So, does it mean we need to keep both the list and dictionary?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks. \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g41009cdd223f57f8486a582cd68f081e","title":"Assignment 1: Tokenize_hashtag() clarifications","type":"DiscussionTopic","content":"\u003cp\u003eHi staffs, \u003c/p\u003e\r\n\u003cp\u003eI have some questions about question 3 on Tokenize_hashtag() function:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eThe instruction only says to lemmatize the token before matching to the list of words. But there are some words in the list with uppercase letter e.g. Amazon and it will not be matched with #amazon. So, do we need to convert both the hashtags and list of words to lowercase prior to matching?\u003c/li\u003e\r\n\u003cli\u003eThere are words that aren't in the given list of words e.g. 'proud'.  Should I just default to single character matching as the instruction said?\u003c/li\u003e\r\n\u003cli\u003eShould I add the lemma or the full inflected form to the result word tokens list?\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eThanks!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g9549c2e797fff3eead698ebf06c28bb3","title":"Suggestions for summarisations and topic modelling lectures","type":"DiscussionTopic","content":"\u003cp\u003eHi!\u003c/p\u003e\r\n\u003cp\u003eI was wondering whether it would be possible to still upload the lectures (say, last year's lectures) for summarisations and topic modelling but set them to not examinable? They seem very interesting and important. For example, apply summarisation techniques to covid-19 papers!\u003c/p\u003e\r\n\u003cp\u003e(and we kinda paid for 12 weeks......)\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g62d3947bb9f2dbcb8ad6c1eb08a5aa23","title":"Q3 - hashtags","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team, \u003c/p\u003e\r\n\u003cp\u003eI would be really grateful if you can help me with some doubts.\u003c/p\u003e\r\n\u003cp\u003eI have 3 questions:\u003c/p\u003e\r\n\u003cp\u003eQuestion 1:\u003c/p\u003e\r\n\u003cp\u003eThe output of my q1 and q2 is a tokenised list of list of the form [[['sent1_word1', 'sent1_word2', ] , ['sent2_word1',]] ,  [['sent3_word1', 'sent3_word2',]  , ['sent4_word1','sent4_word2']] , [[],[]],  [[],[]]] and so on. The length is 500 and 1000 for source-tweets and reactions respectively. Is this correct?\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eQuestion 2:\u003c/p\u003e\r\n\u003cp\u003eI run into the following error when I compile the program to generate the unique hashtags,  is it because the above output is incorrect?\u003c/p\u003e\r\n\u003cpre\u003e\u003cspan class=\"ansi-red-fg\"\u003e---------------------------------------------------------------------------\u003c/span\u003e\r\n\u003cspan class=\"ansi-red-fg\"\u003eAttributeError\u003c/span\u003e                            Traceback (most recent call last)\r\n\u003cspan class=\"ansi-green-fg\"\u003e\u0026lt;ipython-input-88-99dd183a37a6\u0026gt;\u003c/span\u003e in \u003cspan class=\"ansi-cyan-fg\"\u003e\u0026lt;module\u0026gt;\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      7\u003c/span\u003e     \u003cspan class=\"ansi-green-fg\"\u003ereturn\u003c/span\u003e hashtags\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      8\u003c/span\u003e \r\n\u003cspan class=\"ansi-green-fg\"\u003e----\u0026gt; 9\u003c/span\u003e hashtags \u003cspan class=\"ansi-blue-fg\"\u003e=\u003c/span\u003e get_all_hashtags\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003epreprocessed_rumour_events \u003cspan class=\"ansi-blue-fg\"\u003e+\u003c/span\u003e preprocessed_nonrumour_events\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e     10\u003c/span\u003e print\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e\"Number of hashtags =\"\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e,\u003c/span\u003e len\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003ehashtags\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\r\n\u003cspan class=\"ansi-green-fg\"\u003e\u0026lt;ipython-input-88-99dd183a37a6\u0026gt;\u003c/span\u003e in \u003cspan class=\"ansi-cyan-fg\"\u003eget_all_hashtags\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e(events)\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      2\u003c/span\u003e     hashtags \u003cspan class=\"ansi-blue-fg\"\u003e=\u003c/span\u003e set\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e[\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e]\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      3\u003c/span\u003e     \u003cspan class=\"ansi-green-fg\"\u003efor\u003c/span\u003e event \u003cspan class=\"ansi-green-fg\"\u003ein\u003c/span\u003e events\u003cspan class=\"ansi-blue-fg\"\u003e:\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-fg\"\u003e----\u0026gt; 4\u003c/span\u003e         \u003cspan class=\"ansi-green-fg\"\u003efor\u003c/span\u003e word\u003cspan class=\"ansi-blue-fg\"\u003e,\u003c/span\u003e frequency \u003cspan class=\"ansi-green-fg\"\u003ein\u003c/span\u003e event\u003cspan class=\"ansi-blue-fg\"\u003e.\u003c/span\u003eitems\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e:\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      5\u003c/span\u003e             \u003cspan class=\"ansi-green-fg\"\u003eif\u003c/span\u003e word\u003cspan class=\"ansi-blue-fg\"\u003e.\u003c/span\u003estartswith\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e\"#\"\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e:\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      6\u003c/span\u003e                 hashtags\u003cspan class=\"ansi-blue-fg\"\u003e.\u003c/span\u003eadd\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003eword\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\r\n\u003cspan class=\"ansi-red-fg\"\u003eAttributeError\u003c/span\u003e: 'list' object has no attribute 'items'\u003c/pre\u003e\r\n\u003cpre\u003e\u003cspan class=\"ansi-red-fg\"\u003e---------------------------------------------------------------------------\u003c/span\u003e\r\n\u003cspan class=\"ansi-red-fg\"\u003eAttributeError\u003c/span\u003e                            Traceback (most recent call last)\r\n\u003cspan class=\"ansi-green-fg\"\u003e\u0026lt;ipython-input-88-99dd183a37a6\u0026gt;\u003c/span\u003e in \u003cspan class=\"ansi-cyan-fg\"\u003e\u0026lt;module\u0026gt;\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      7\u003c/span\u003e     \u003cspan class=\"ansi-green-fg\"\u003ereturn\u003c/span\u003e hashtags\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      8\u003c/span\u003e \r\n\u003cspan class=\"ansi-green-fg\"\u003e----\u0026gt; 9\u003c/span\u003e hashtags \u003cspan class=\"ansi-blue-fg\"\u003e=\u003c/span\u003e get_all_hashtags\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003epreprocessed_rumour_events \u003cspan class=\"ansi-blue-fg\"\u003e+\u003c/span\u003e preprocessed_nonrumour_events\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e     10\u003c/span\u003e print\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e\"Number of hashtags =\"\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e,\u003c/span\u003e len\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003ehashtags\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\r\n\u003cspan class=\"ansi-green-fg\"\u003e\u0026lt;ipython-input-88-99dd183a37a6\u0026gt;\u003c/span\u003e in \u003cspan class=\"ansi-cyan-fg\"\u003eget_all_hashtags\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e(events)\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      2\u003c/span\u003e     hashtags \u003cspan class=\"ansi-blue-fg\"\u003e=\u003c/span\u003e set\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e[\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e]\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      3\u003c/span\u003e     \u003cspan class=\"ansi-green-fg\"\u003efor\u003c/span\u003e event \u003cspan class=\"ansi-green-fg\"\u003ein\u003c/span\u003e events\u003cspan class=\"ansi-blue-fg\"\u003e:\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-fg\"\u003e----\u0026gt; 4\u003c/span\u003e         \u003cspan class=\"ansi-green-fg\"\u003efor\u003c/span\u003e word\u003cspan class=\"ansi-blue-fg\"\u003e,\u003c/span\u003e frequency \u003cspan class=\"ansi-green-fg\"\u003ein\u003c/span\u003e event\u003cspan class=\"ansi-blue-fg\"\u003e.\u003c/span\u003eitems\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e:\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      5\u003c/span\u003e             \u003cspan class=\"ansi-green-fg\"\u003eif\u003c/span\u003e word\u003cspan class=\"ansi-blue-fg\"\u003e.\u003c/span\u003estartswith\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e\"#\"\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\u003cspan class=\"ansi-blue-fg\"\u003e:\u003c/span\u003e\r\n\u003cspan class=\"ansi-green-intense-fg ansi-bold\"\u003e      6\u003c/span\u003e                 hashtags\u003cspan class=\"ansi-blue-fg\"\u003e.\u003c/span\u003eadd\u003cspan class=\"ansi-blue-fg\"\u003e(\u003c/span\u003eword\u003cspan class=\"ansi-blue-fg\"\u003e)\u003c/span\u003e\r\n\r\n\u003cspan class=\"ansi-red-fg\"\u003eAttributeError\u003c/span\u003e: 'list' object has no attribute 'items'\u003c/pre\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eQuestion 3:\u003c/p\u003e\r\n\u003cp\u003eIf  I modify the given code, I get the number of unique hashtags.. am I allowed to do that? An example is shown below:\u003c/p\u003e\r\n\u003cp\u003eCode modified: \u003c/p\u003e\r\n\u003cp\u003edef get_all_hashtags(events):\u003cbr\u003ehashtags = set([])\u003cbr\u003efor event in events:\u003cbr\u003efor event_again in event:\u003cbr\u003efor word in event_again:\u003cbr\u003eif word.startswith(\"#\"):\u003cbr\u003ehashtags.add(word)\u003cbr\u003ereturn hashtags\u003c/p\u003e\r\n\u003cp\u003ehashtags = get_all_hashtags(preprocessed_rumour_events + preprocessed_nonrumour_events)\u003cbr\u003e#print(hashtags)\u003cbr\u003eprint(\"Number of hashtags =\", len(hashtags))\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eoutput:\u003c/p\u003e\r\n\u003cpre\u003eNumber of hashtags = 1829\u003c/pre\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g0d9a24ffa5ad89ac1c6ac85c2593de1a","title":"Assignment1 - Q2","type":"DiscussionTopic","content":"\u003cdiv\u003eIn Q2\u003c/div\u003e1. If there is two tokens, ‘sports’ and ‘Sports’, should we count them as a same token or two different tokens?\u003cdiv\u003e\u003cbr\u003e\u003c/div\u003e\u003cdiv\u003e2. And also should we do lowercase when removing stopwords? (Eg. ‘the’ in stopwords but ‘The’ not)\u003c/div\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g41d209c16b9c7eb04b9172d8e6cf505c","title":"Assignment1-Q6 accuracy","type":"DiscussionTopic","content":"\u003cp\u003eIn my results, some accuracy numbers with different hyper-parameters are equal. Is that possible or might be some errors in my code? Thanks for help.\u003c/p\u003e","lockAt":"2020-04-02T23:59:59+11:00","unlockAt":"2020-04-02T00:00:00+11:00","graded":false},{"exportId":"g531d523f701401d03c97b84980f1e7f1","title":"About package","type":"DiscussionTopic","content":"\u003cp\u003eHi teaching team,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eI saw some comments on discussion board. Jey Han says wen can use sklearn. so can we import like this:\u003c/p\u003e\r\n\u003cp\u003efrom sklearn.metrics import precision_recall_fscore_support\u003c/p\u003e\r\n\u003cp\u003efrom sklearn.metrics import accuracy_score\u003c/p\u003e\r\n\u003cp\u003efrom sklearn.model_selection import train_test_split\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eThanks!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g5105bf63141164475b03802327c96550","title":"About performance","type":"DiscussionTopic","content":"\u003cp\u003eHello\u003c/p\u003e\r\n\u003cp\u003eI would like to know how long should the entire file take to run?\u003c/p\u003e\r\n\u003cp\u003eI notice that when I run it for the first time it takes longer than running for a 2nd or 3rd time (probably because it uses memory, not sure)\u003c/p\u003e\r\n\u003cp\u003eThe downloading and extraction part takes around 2 minutes, and I if we lowercase the entire wordnet dictionary it takes like a minute or more. \u003c/p\u003e\r\n\u003cp\u003eThanks\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g0042ed73eb23f5c15c05da165113ca68","title":"Question about BPE","type":"DiscussionTopic","content":"\u003cp\u003eHi there,\u003c/p\u003e\r\n\u003cp\u003eAfter running \u003cem\u003ek\u003c/em\u003e merges of BPE, we will have a large vocabulary. But with this vocabulary, how do we split words in a sentence into sub-words? Using longest match? E.g. for the word \"cases\", if the longest match in the current vocabulary is \"cas\", then we will split it into \"cas\" first, then try to match \"es\"? So the matching process is not about the pair frequency any more, is this the right understanding?\u003c/p\u003e\r\n\u003cp\u003eThank you very much!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g3c203fa08ec1a2f4a63b2509d03032de","title":"Assignment 1 Question4","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\r\n\u003cp\u003eI have question related stop_words\u003c/p\u003e\r\n\u003cp\u003eI know someone already asked related to this topic, however the thread is closed to comments\u003c/p\u003e\r\n\u003cp\u003eIt is answered that we should not remove stop_words included in hashtag tokens as it's not in instruction. \u003c/p\u003e\r\n\u003cp\u003edoes it mean in question 4 do we need to count the frequency of stop_words as well while we skipped in those in question 2? \u003c/p\u003e\r\n\u003cp\u003eThank you.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gf347aac26fbf812737a415078aa41c32","title":"Can I use counter in Q2?","type":"DiscussionTopic","content":"\u003cp\u003eHi, \u003c/p\u003e\r\n\u003cp\u003eCan I import counter from collection and use it for calculating word frequency?\u003c/p\u003e\r\n\u003cp\u003eShuyu\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g474c7203ba19cbda7b45096d49d9e40b","title":"About the  reversed maxMach resultes","type":"DiscussionTopic","content":"\u003cp\u003eHi,teaching team \u003c/p\u003e\r\n\u003cp\u003eI did the reversed maxMach from max range to min range , like \"cate\",\"ate\"... and the resultes shows\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"max-width: 320px; max-height: 320px;\" src=\"https://canvas.lms.unimelb.edu.au/users/26557/files/2923288/preview?wrap=1\u0026amp;verifier=V7qAeqgw6XTUVYBN6hkGSAosHE9iqG0PBBzJov3A\" alt=\"1585830415.png\"\u003e\u003c/p\u003e\r\n\u003cp\u003eDo I conduct  the reversed maxMach correctly ?\u003c/p\u003e\r\n\u003cp\u003eAnother question: My Q7 resultes(  around 0.5-0.6)  are 0.2 less than the accuracy in Q6. Is it accptable in this assignment ?\u003c/p\u003e\r\n\u003cp\u003eThanks!\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"gc8b795a009965cf18789111187d9ab20","title":"jupyter notebook assertion error","type":"DiscussionTopic","content":"\u003cp\u003eDear teaching team,\u003c/p\u003e\u003cp\u003e \u003c/p\u003e\u003cp\u003eI'm trying to learn code with notebook to get instruction however, it throws assertion error\u003c/p\u003e\u003cp\u003ehow can I fix this? \u003c/p\u003e\u003cp\u003eThank you\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://canvas.lms.unimelb.edu.au/users/18832/files/2804770/preview?wrap=1\u0026amp;verifier=wQnn4W6ObFQg5Ttq1uPTbUciyMhDprDQpOLgVGiX\" alt=\"assertion error.PNG\" width=\"640\" height=\"156\"\u003e\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g020df2068ca69ce58048a23b82c0f69a","title":"Assignment 1 - Q4: stopwords in hashtags","type":"DiscussionTopic","content":"\u003cp\u003eHi,\u003c/p\u003e\r\n\u003cp\u003eIf there are stopwords in the tokenized hashtag tokens, do we add them to the BOW counts in Q4? e.g. the hashtag \"#speakup\" becomes [\"#\", \"speak\", \"up\"] and \"up\" is in the set of stopwords. In this case would we increment the counts of \"#\", \"speak\" and \"up\", or just \"#\" and \"speak\"?\u003c/p\u003e\r\n\u003cp\u003eThanks.\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false}],"quizzes":[],"files":[{"type":"file","name":"demo_1.ipynb","size":14992,"files":null},{"type":"file","name":"l2-preprocessing.pdf","size":377897,"files":null},{"type":"file","name":"9-neural-nets.pdf","size":750312,"files":null},{"type":"folder","name":"unfiled","size":null,"files":[]},{"type":"file","name":"l14-context-free-grammar.pdf","size":1191975,"files":null},{"type":"file","name":"l3-ngram.pdf","size":1059953,"files":null},{"type":"file","name":"l8-recurrent.pdf","size":4636599,"files":null},{"type":"file","name":"l12-discourse.pdf","size":1444304,"files":null},{"type":"folder","name":"course_image","size":null,"files":[]},{"type":"file","name":"l16-dependency.pdf","size":2756907,"files":null},{"type":"file","name":"l1-intro.pdf","size":2691676,"files":null},{"type":"file","name":"7-1-optimization.pdf","size":286776,"files":null},{"type":"file","name":"10-backprop_v3.pdf","size":425366,"files":null},{"type":"file","name":"l6-hmm.pdf","size":1245676,"files":null},{"type":"file","name":"l15-probabilistic-cfg.pdf","size":1973173,"files":null},{"type":"file","name":"l13-formal-language-theory.pdf","size":2619320,"files":null},{"type":"file","name":"l10-distributional-semantics.pdf","size":2082881,"files":null},{"type":"file","name":"g15.pdf","size":718508,"files":null},{"type":"file","name":"demo_1_data.csv","size":403,"files":null},{"type":"file","name":"l9-lexical-semantics.pdf","size":1442869,"files":null},{"type":"file","name":"l7-feedforward.pdf","size":2701209,"files":null},{"type":"file","name":"l18-information-extraction.pdf","size":1562269,"files":null},{"type":"file","name":"7-2-logisticregression.pdf","size":302328,"files":null},{"type":"file","name":"8-perceptron.pdf","size":1937039,"files":null},{"type":"folder","name":"Uploaded Media","size":null,"files":[{"type":"file","name":"workshop02-slides.pdf","size":443170,"files":null},{"type":"file","name":"COMP90042_Week_3.pdf","size":712631,"files":null},{"type":"file","name":"workshop_slides_03-3.pdf","size":596535,"files":null},{"type":"file","name":"workshop03-slides.pdf","size":333225,"files":null},{"type":"file","name":"COMP90042_Week_2.pdf","size":28224,"files":null},{"type":"file","name":"workshop_slides_02.pdf","size":31662,"files":null}]},{"type":"file","name":"l5-pos.pdf","size":996766,"files":null},{"type":"file","name":"l4-text-classification.pdf","size":845741,"files":null},{"type":"file","name":"l11-contextual-representation.pdf","size":7167836,"files":null},{"type":"file","name":"e18.pdf","size":4589892,"files":null},{"type":"file","name":"l17-machine-translation.pdf","size":5703183,"files":null},{"type":"folder","name":"workshops","size":null,"files":[{"type":"folder","name":"slides","size":null,"files":[{"type":"file","name":"Week7.pptx","size":4408704,"files":null},{"type":"file","name":"Week5.pptx","size":3359087,"files":null},{"type":"file","name":"Week5_zz.pptx","size":4029664,"files":null},{"type":"file","name":"Week8_updated.pptx","size":3598189,"files":null},{"type":"folder","name":"zenan","size":null,"files":[{"type":"file","name":"COMP90042_2020_Week3.pdf","size":465179,"files":null},{"type":"file","name":"COMP90042_2020_Week2.pdf","size":956688,"files":null}]},{"type":"file","name":"Week4.pptx","size":4035163,"files":null}]},{"type":"folder","name":"notebooks","size":null,"files":[{"type":"file","name":"07-deep-learning.ipynb","size":32791,"files":null},{"type":"file","name":"07-yelp-dataset.txt","size":61320,"files":null},{"type":"file","name":"08-lexical-semantics.ipynb","size":21823,"files":null},{"type":"file","name":"03-classification.ipynb","size":24356,"files":null},{"type":"file","name":"Week6.pptx","size":5639353,"files":null},{"type":"file","name":"01-preprocessing.ipynb","size":10078,"files":null},{"type":"file","name":"02-bpe.ipynb","size":9951,"files":null},{"type":"file","name":"09-distributional-semantics.ipynb","size":13585,"files":null},{"type":"file","name":"10-dataset.zip","size":1496200,"files":null},{"type":"file","name":"10-bert.ipynb","size":51314,"files":null},{"type":"file","name":"02-bpe-solution.ipynb","size":110782,"files":null},{"type":"file","name":"06-hmm.ipynb","size":21491,"files":null},{"type":"file","name":"04-ngram.ipynb","size":20288,"files":null},{"type":"file","name":"05-pos-tagging.ipynb","size":20889,"files":null}]},{"type":"folder","name":"worksheets","size":null,"files":[{"type":"file","name":"workshop-03.pdf","size":86815,"files":null},{"type":"file","name":"workshop-04.pdf","size":86737,"files":null},{"type":"file","name":"solutions-04.pdf","size":134153,"files":null},{"type":"file","name":"solutions-05.pdf","size":101125,"files":null},{"type":"file","name":"workshop-02.pdf","size":56452,"files":null},{"type":"file","name":"workshop-08.pdf","size":55882,"files":null},{"type":"file","name":"workshop-06.pdf","size":72162,"files":null},{"type":"file","name":"workshop-07.pdf","size":65298,"files":null},{"type":"file","name":"workshop-09.pdf","size":57451,"files":null},{"type":"file","name":"solutions-06.pdf","size":112754,"files":null},{"type":"file","name":"workshop-05.pdf","size":62632,"files":null},{"type":"file","name":"solutions-07.pdf","size":79979,"files":null},{"type":"file","name":"solutions-08.pdf","size":114108,"files":null},{"type":"file","name":"solutions-02.pdf","size":65941,"files":null},{"type":"file","name":"solutions-03.pdf","size":112010,"files":null}]}]}]}